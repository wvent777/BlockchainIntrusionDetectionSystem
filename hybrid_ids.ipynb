{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HYBRID INTRUSION DETECTION SYSTEM (PLACEHOLDER)\n",
    "\n",
    "This is the code for the paper \" \"\n",
    "\n",
    "Author: William S. Ventura (w.stephan.ventura@gmail.com)\n",
    "Organization: Whiting School of Engineering, Johns Hopkins University"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IMPORT LIBRARIES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 06:06:12.756035: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn_genetic import GAFeatureSelectionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn_genetic.plots import plot_fitness_evolution\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import hdbscan\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading in the CIC_Collection Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The CIC Collection Dataset is a combination of CIC-IDS2017, CIC-DoS2017, CSE-CIC-IDS2018 and CIC-DDoS2019. Publicly available on Kaggle @ https://www.kaggle.com/code/dhoogla/cic-collection-00-clean-up\n",
    "\n",
    "Note: The cleaned up version of this collection has removed contaminated features found in the CIC datasets and other NIDS datasets which have equal blind predictive power across all available attack classes, despite having had access to only one attack class during training.\n",
    "The features which contaminate the CIC collection dataset in the aforementioned way are in order of severity:\n",
    "\n",
    "    PSH Flag Count, ECE Flag Count, RST Flag Count, ACK Flag Count\n",
    "    Fwd Packet Length Min\n",
    "    Bwd Packet Length Min\n",
    "    Packet Length Min\n",
    "    Protocol\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: At the start of this project the original cic-collection was used, it was later modified to use the cleaned up version, both .parquet files are available in the \"ids_data\" folder\n",
    "\n",
    "Note: Due to the massive size of the dataset and hardware limitations, a sampled subset of CIC_Collection is used. The subsets are in the \"ids_data\" folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_parquet(\"./ids_data/cic-collection.parquet\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(9167581, 78)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns (Extra Label Column)\n",
    "df.drop(columns=[\"Label\"], axis=1, inplace=True)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Improving the CIC Collection\n",
    "###  1.Removing contaminating features\n",
    "### Improved CIC will be compared against feature selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Protocol', 'Flow Duration', 'Total Fwd Packets',\n       'Total Backward Packets', 'Fwd Packets Length Total',\n       'Bwd Packets Length Total', 'Fwd Packet Length Max',\n       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n       'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n       'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n       'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n       'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate',\n       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n       'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes',\n       'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n       'Idle Min', 'ClassLabel'],\n      dtype='object')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(9167581, 69)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_improved = df.drop(columns=['PSH Flag Count', 'ECE Flag Count', 'RST Flag Count', 'ACK Flag Count', 'Fwd Packet Length Min', 'Bwd Packet Length Min', 'Packet Length Min', 'Protocol', 'Down/Up Ratio'], axis=0)\n",
    "df_improved.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Removing features with no separating power\n",
    "\n",
    "For the CIC collection, 11 features with 0 predictive power have been identified based on the findings in \"Discovering Non-Metadata Contaminant Features in Intrusion Detection Datasets\"\n",
    "\n",
    "Link:\n",
    "https://www.researchgate.net/publication/363265363_Discovering_Non-Metadata_Contaminant_Features_in_Intrusion_Detection_Datasets?channel=doi&linkId=6314afa85eed5e4bd1478531&showFulltext=true"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(9167581, 58)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_improved = df_improved.drop(columns=['Bwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd PSH Flags', 'Bwd URG Flags', 'CWE Flag Count', 'FIN Flag Count', 'Fwd Avg Bulk Rate', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd URG Flags'])\n",
    "df_improved.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df_improved.to_parquet('./ids_data/cic-collection-clean.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9167581 entries, 0 to 9167580\n",
      "Data columns (total 78 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   Protocol                  int8   \n",
      " 1   Flow Duration             int64  \n",
      " 2   Total Fwd Packets         int32  \n",
      " 3   Total Backward Packets    int32  \n",
      " 4   Fwd Packets Length Total  float64\n",
      " 5   Bwd Packets Length Total  float64\n",
      " 6   Fwd Packet Length Max     float64\n",
      " 7   Fwd Packet Length Min     float32\n",
      " 8   Fwd Packet Length Mean    float32\n",
      " 9   Fwd Packet Length Std     float32\n",
      " 10  Bwd Packet Length Max     float64\n",
      " 11  Bwd Packet Length Min     float32\n",
      " 12  Bwd Packet Length Mean    float32\n",
      " 13  Bwd Packet Length Std     float32\n",
      " 14  Flow Bytes/s              float64\n",
      " 15  Flow Packets/s            float64\n",
      " 16  Flow IAT Mean             float32\n",
      " 17  Flow IAT Std              float32\n",
      " 18  Flow IAT Max              float64\n",
      " 19  Flow IAT Min              float64\n",
      " 20  Fwd IAT Total             float64\n",
      " 21  Fwd IAT Mean              float32\n",
      " 22  Fwd IAT Std               float32\n",
      " 23  Fwd IAT Max               float64\n",
      " 24  Fwd IAT Min               float64\n",
      " 25  Bwd IAT Total             float64\n",
      " 26  Bwd IAT Mean              float32\n",
      " 27  Bwd IAT Std               float32\n",
      " 28  Bwd IAT Max               float64\n",
      " 29  Bwd IAT Min               float64\n",
      " 30  Fwd PSH Flags             int8   \n",
      " 31  Bwd PSH Flags             int8   \n",
      " 32  Fwd URG Flags             int8   \n",
      " 33  Bwd URG Flags             int8   \n",
      " 34  Fwd Header Length         int64  \n",
      " 35  Bwd Header Length         int64  \n",
      " 36  Fwd Packets/s             float32\n",
      " 37  Bwd Packets/s             float32\n",
      " 38  Packet Length Min         float32\n",
      " 39  Packet Length Max         float64\n",
      " 40  Packet Length Mean        float32\n",
      " 41  Packet Length Std         float32\n",
      " 42  Packet Length Variance    float32\n",
      " 43  FIN Flag Count            int8   \n",
      " 44  SYN Flag Count            int8   \n",
      " 45  RST Flag Count            int8   \n",
      " 46  PSH Flag Count            int8   \n",
      " 47  ACK Flag Count            int8   \n",
      " 48  URG Flag Count            int8   \n",
      " 49  CWE Flag Count            int8   \n",
      " 50  ECE Flag Count            int8   \n",
      " 51  Down/Up Ratio             float32\n",
      " 52  Avg Packet Size           float32\n",
      " 53  Avg Fwd Segment Size      float32\n",
      " 54  Avg Bwd Segment Size      float32\n",
      " 55  Fwd Avg Bytes/Bulk        int8   \n",
      " 56  Fwd Avg Packets/Bulk      int8   \n",
      " 57  Fwd Avg Bulk Rate         int8   \n",
      " 58  Bwd Avg Bytes/Bulk        int8   \n",
      " 59  Bwd Avg Packets/Bulk      int8   \n",
      " 60  Bwd Avg Bulk Rate         int8   \n",
      " 61  Subflow Fwd Packets       int32  \n",
      " 62  Subflow Fwd Bytes         int32  \n",
      " 63  Subflow Bwd Packets       int32  \n",
      " 64  Subflow Bwd Bytes         int32  \n",
      " 65  Init Fwd Win Bytes        int32  \n",
      " 66  Init Bwd Win Bytes        int32  \n",
      " 67  Fwd Act Data Packets      int32  \n",
      " 68  Fwd Seg Size Min          int32  \n",
      " 69  Active Mean               float32\n",
      " 70  Active Std                float32\n",
      " 71  Active Max                float64\n",
      " 72  Active Min                float64\n",
      " 73  Idle Mean                 float32\n",
      " 74  Idle Std                  float32\n",
      " 75  Idle Max                  float64\n",
      " 76  Idle Min                  float64\n",
      " 77  ClassLabel                object \n",
      "dtypes: float32(26), float64(19), int32(10), int64(3), int8(19), object(1)\n",
      "memory usage: 3.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Z-Score Normalization\n",
    "# Original Data\n",
    "features = df.dtypes[df.dtypes != 'object'].index\n",
    "df[features] = df[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# Fill nan values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Improved Data\n",
    "features_1 = df_improved.dtypes[df_improved.dtypes != 'object'].index\n",
    "df_improved[features_1] = df_improved[features_1].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# Fill nan values with 0\n",
    "df_improved = df_improved.fillna(0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0    7186189\n3    1234729\n4     397344\n1     145968\n2     103244\n5      94857\n7       2995\n6       2255\nName: ClassLabel, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding labels of original data\n",
    "labelencoder = LabelEncoder()\n",
    "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])\n",
    "df.ClassLabel.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(9167581, 78)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0    7186189\n3    1234729\n4     397344\n1     145968\n2     103244\n5      94857\n7       2995\n6       2255\nName: ClassLabel, dtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding labels of improved data\n",
    "labelencoder = LabelEncoder()\n",
    "df_improved.iloc[:, -1] = labelencoder.fit_transform(df_improved.iloc[:, -1])\n",
    "df_improved.ClassLabel.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(9167581, 58)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_improved.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Sampling\n",
    "Since the data is too large, a small subset will be generated to train the model using HDBSCAN clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Sampled Shape: (91676, 78)\n"
     ]
    }
   ],
   "source": [
    "# Can Adjust Sample Size, but HDBSCAN was taking too long with the original data set\n",
    "# Going to resample twice\n",
    "df_sample1 = df.sample(frac=0.01, random_state=1)\n",
    "print(f\"DF Sampled Shape: {df_sample1.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Minors are 5: Infiltration, 7: Webattack, 6: Portscan\n",
    "# Keep the minor size and sampling from the remaining major classes\n",
    "df_minor = df_sample1[(df_sample1['ClassLabel'] == 5) | \\\n",
    "                      (df_sample1['ClassLabel'] == 7) | (df_sample1['ClassLabel'] == 6)]\n",
    "df_major = df_sample1.drop(df_minor.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(90599, 77)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_major.drop(['ClassLabel'], axis=1)\n",
    "y = df_major.iloc[:, -1].values.reshape(-1, 1)\n",
    "y = np.ravel(y)\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start clusturing\n",
      "-1       26211\n",
      " 1435     2905\n",
      " 870       710\n",
      " 2255      618\n",
      " 2429      578\n",
      "         ...  \n",
      " 2451        5\n",
      " 1838        5\n",
      " 493         5\n",
      " 305         5\n",
      " 1013        5\n",
      "Name: ClusterLabels, Length: 3983, dtype: int64\n",
      "done clustering \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Sampling the original dataset\n",
    "# Use HDBSCAN to Cluster the data samples\n",
    "print('start clusturing')\n",
    "clusterer = hdbscan.HDBSCAN()\n",
    "clusterer.fit(X)\n",
    "cluster_labels = clusterer.labels_\n",
    "df_major[\"ClusterLabels\"] = cluster_labels\n",
    "print(df_major[\"ClusterLabels\"].value_counts())\n",
    "print(\"done clustering \\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "cols = list(df_major)\n",
    "# with 2 layer of metadata removed it is 58, without it is 79\n",
    "cols.insert(79, cols.pop(cols.index('ClassLabel')))\n",
    "df_major = df_major.loc[:, cols]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "         Protocol  Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n6300475  1.676793      -0.024155          -0.018775               -0.012927   \n5913184 -0.568137      -0.017002          -0.017323               -0.009483   \n423760  -0.568137      -0.024212          -0.019259               -0.014650   \n1616769 -0.568137       0.156313          -0.010548                0.011187   \n5473594 -0.568137      -0.024212          -0.018291               -0.014650   \n...           ...            ...                ...                     ...   \n3007592 -0.568137       0.099460          -0.018775               -0.016372   \n6771053 -0.568137      -0.023580          -0.018775               -0.016372   \n2842438 -0.568137      -0.024178          -0.018291               -0.009483   \n5876236 -0.568137      -0.017600          -0.017323               -0.011205   \n2162949  1.676793      -0.024212          -0.019259               -0.014650   \n\n         Fwd Packets Length Total  Bwd Packets Length Total  \\\n6300475                 -0.023878                 -0.007616   \n5913184                 -0.013505                 -0.007278   \n423760                  -0.024691                 -0.007813   \n1616769                 -0.009007                 -0.005949   \n5473594                 -0.024320                 -0.007813   \n...                           ...                       ...   \n3007592                 -0.024691                 -0.007813   \n6771053                 -0.024691                 -0.007813   \n2842438                 -0.024452                 -0.007061   \n5876236                 -0.013505                 -0.007526   \n2162949                 -0.023722                 -0.007662   \n\n         Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n6300475              -0.519466               0.110412               -0.339401   \n5913184               1.275878              -0.269129                0.758992   \n423760               -0.587215              -0.269129               -0.583488   \n1616769               0.283557              -0.269129               -0.088134   \n5473594              -0.525444              -0.269129               -0.509305   \n...                        ...                    ...                     ...   \n3007592              -0.587215              -0.269129               -0.583488   \n6771053              -0.587215              -0.269129               -0.583488   \n2842438              -0.547363              -0.269129               -0.535628   \n5876236               1.275878              -0.269129                0.758992   \n2162949              -0.425813               0.635072               -0.001986   \n\n         Fwd Packet Length Std  Bwd Packet Length Max  Bwd Packet Length Min  \\\n6300475              -0.543296              -0.407501               1.810705   \n5913184               1.634291              -0.223685              -0.473586   \n423760               -0.543296              -0.514233              -0.473586   \n1616769               0.309289               0.160043              -0.473586   \n5473594              -0.450089              -0.514233              -0.473586   \n...                        ...                    ...                    ...   \n3007592              -0.543296              -0.514233              -0.473586   \n6771053              -0.543296              -0.514233              -0.473586   \n2842438              -0.483162               0.302353              -0.473586   \n5876236               1.634291              -0.202508              -0.473586   \n2162949              -0.543296              -0.350747               3.025367   \n\n         Bwd Packet Length Mean  Bwd Packet Length Std  Flow Bytes/s  \\\n6300475               -0.201760              -0.501630     -0.044793   \n5913184               -0.078187              -0.089415     -0.044922   \n423760                -0.543963              -0.501630     -0.044928   \n1616769               -0.138616               0.166299     -0.044927   \n5473594               -0.543963              -0.501630     -0.043752   \n...                         ...                    ...           ...   \n3007592               -0.543963              -0.501630     -0.044928   \n6771053               -0.543963              -0.501630     -0.044928   \n2842438                0.110568               0.501685     -0.044235   \n5876236               -0.210813              -0.059370     -0.044923   \n2162949               -0.019795              -0.501630     -0.034537   \n\n         Flow Packets/s  Flow IAT Mean  Flow IAT Std  Flow IAT Max  \\\n6300475       -0.104969      -0.015411     -0.005265     -0.011938   \n5913184       -0.105976      -0.013454     -0.001905     -0.006988   \n423760         0.122823      -0.015453     -0.005312     -0.011980   \n1616769       -0.105991      -0.003678      0.005398     -0.000357   \n5473594       -0.013365      -0.015453     -0.005312     -0.011979   \n...                 ...            ...           ...           ...   \n3007592       -0.105994       0.258664     -0.005312      0.080548   \n6771053       -0.105948      -0.014052     -0.005312     -0.011507   \n2842438       -0.102984      -0.015441     -0.005292     -0.011955   \n5876236       -0.105977      -0.013358     -0.001728     -0.007106   \n2162949       -0.059679      -0.015452     -0.005312     -0.011979   \n\n         Flow IAT Min  Fwd IAT Total  Fwd IAT Mean  Fwd IAT Std  Fwd IAT Max  \\\n6300475     -0.002767      -0.023239     -0.017209    -0.005652    -0.011422   \n5913184     -0.002767      -0.016085     -0.013337    -0.000905    -0.006472   \n423760      -0.002767      -0.023295     -0.017335    -0.005652    -0.011464   \n1616769     -0.002767       0.157841      0.004902     0.005178     0.000159   \n5473594     -0.002767      -0.023295     -0.017334    -0.005651    -0.011464   \n...               ...            ...           ...          ...          ...   \n3007592      0.078858       0.100304      0.256765    -0.005652     0.081064   \n6771053     -0.002350      -0.022663     -0.015934    -0.005652    -0.010991   \n2842438     -0.002767      -0.023295     -0.017334    -0.005651    -0.011463   \n5876236     -0.002767      -0.016683     -0.013669    -0.000923    -0.006590   \n2162949     -0.002767      -0.023295     -0.017335    -0.005652    -0.011464   \n\n         Fwd IAT Min  Bwd IAT Total  Bwd IAT Mean  Bwd IAT Std  Bwd IAT Max  \\\n6300475    -0.002981      -0.334857     -0.200174    -0.262981    -0.275231   \n5913184    -0.003018      -0.323544     -0.182879    -0.239616    -0.258876   \n423760     -0.003018      -0.334876     -0.200260    -0.262981    -0.275270   \n1616769    -0.003018       3.897836      1.093564     0.642553     0.492960   \n5473594    -0.003018      -0.334876     -0.200260    -0.262981    -0.275270   \n...              ...            ...           ...          ...          ...   \n3007592     0.078606      -0.334876     -0.200260    -0.262981    -0.275270   \n6771053    -0.002601      -0.334876     -0.200260    -0.262981    -0.275270   \n2842438    -0.003018      -0.334081     -0.199041    -0.260307    -0.273627   \n5876236    -0.003018      -0.332980     -0.195898    -0.254990    -0.271281   \n2162949    -0.003018      -0.334876     -0.200260    -0.262981    -0.275270   \n\n         Bwd IAT Min  Fwd PSH Flags  Bwd PSH Flags  Fwd URG Flags  \\\n6300475    -0.086333      -0.179931      -0.023297      -0.014409   \n5913184    -0.086376      -0.179931      -0.023297      -0.014409   \n423760     -0.086426      -0.179931      -0.023297      -0.014409   \n1616769    -0.086316      -0.179931      -0.023297      -0.014409   \n5473594    -0.086426      -0.179931      -0.023297      -0.014409   \n...              ...            ...            ...            ...   \n3007592    -0.086426      -0.179931      -0.023297      -0.014409   \n6771053    -0.086426      -0.179931      -0.023297      -0.014409   \n2842438    -0.086422      -0.179931      -0.023297      -0.014409   \n5876236    -0.086365      -0.179931      -0.023297      -0.014409   \n2162949    -0.086426      -0.179931      -0.023297      -0.014409   \n\n         Bwd URG Flags  Fwd Header Length  Bwd Header Length  Fwd Packets/s  \\\n6300475            0.0           0.009329           0.004222      -0.093281   \n5913184            0.0           0.009329           0.004232      -0.093808   \n423760             0.0           0.009329           0.004223       0.026202   \n1616769            0.0           0.009330           0.004261      -0.093817   \n5473594            0.0           0.009329           0.004222      -0.020939   \n...                ...                ...                ...            ...   \n3007592            0.0           0.009329           0.004221      -0.093819   \n6771053            0.0           0.009329           0.004221      -0.093771   \n2842438            0.0           0.009329           0.004228      -0.092466   \n5876236            0.0           0.009329           0.004229      -0.093807   \n2162949            0.0           0.009329           0.004222      -0.069526   \n\n         Bwd Packets/s  Packet Length Min  Packet Length Max  \\\n6300475      -0.091193           0.125578          -0.477361   \n5913184      -0.094031          -0.279262           0.185264   \n423760        0.549481          -0.279262          -0.580564   \n1616769      -0.094070          -0.279262           0.071414   \n5473594       0.036185          -0.279262          -0.555173   \n...                ...                ...                ...   \n3007592      -0.094077          -0.279262          -0.580564   \n6771053      -0.094077          -0.279262          -0.580564   \n2842438      -0.084401          -0.279262           0.209017   \n5876236      -0.094040          -0.279262           0.185264   \n2162949       0.036185           0.685211          -0.422484   \n\n         Packet Length Mean  Packet Length Std  Packet Length Variance  \\\n6300475           -0.340576          -0.463334               -0.203713   \n5913184            0.095845           0.235656               -0.107130   \n423760            -0.679005          -0.600738               -0.206392   \n1616769           -0.187852           0.066182               -0.143281   \n5473594           -0.649369          -0.562935               -0.206189   \n...                     ...                ...                     ...   \n3007592           -0.679005          -0.600738               -0.206392   \n6771053           -0.679005          -0.600738               -0.206392   \n2842438           -0.091056           0.326065               -0.084512   \n5876236            0.013044           0.272796               -0.098119   \n2162949           -0.113363          -0.424415               -0.201981   \n\n         FIN Flag Count  SYN Flag Count  RST Flag Count  PSH Flag Count  \\\n6300475       -0.114025       -0.205288       -0.475313       -0.867342   \n5913184       -0.114025       -0.205288       -0.475313       -0.867342   \n423760        -0.114025       -0.205288       -0.475313       -0.867342   \n1616769       -0.114025       -0.205288       -0.475313        1.152947   \n5473594       -0.114025       -0.205288       -0.475313       -0.867342   \n...                 ...             ...             ...             ...   \n3007592       -0.114025       -0.205288       -0.475313       -0.867342   \n6771053       -0.114025       -0.205288       -0.475313       -0.867342   \n2842438       -0.114025       -0.205288        2.103879        1.152947   \n5876236       -0.114025       -0.205288       -0.475313       -0.867342   \n2162949       -0.114025       -0.205288       -0.475313       -0.867342   \n\n         ACK Flag Count  URG Flag Count  CWE Flag Count  ECE Flag Count  \\\n6300475       -0.620914       -0.193904       -0.049057       -0.473042   \n5913184        1.610529       -0.193904       -0.049057       -0.473042   \n423760         1.610529        5.157202       -0.049057       -0.473042   \n1616769       -0.620914       -0.193904       -0.049057       -0.473042   \n5473594        1.610529       -0.193904       -0.049057       -0.473042   \n...                 ...             ...             ...             ...   \n3007592        1.610529       -0.193904       -0.049057       -0.473042   \n6771053        1.610529       -0.193904       -0.049057       -0.473042   \n2842438       -0.620914       -0.193904       -0.049057        2.113978   \n5876236        1.610529       -0.193904       -0.049057       -0.473042   \n2162949       -0.620914       -0.193904       -0.049057       -0.473042   \n\n         Down/Up Ratio  Avg Packet Size  Avg Fwd Segment Size  \\\n6300475       0.609177        -0.310628             -0.339401   \n5913184      -0.665006         0.089143              0.758992   \n423760        0.609177        -0.696823             -0.583488   \n1616769      -0.665006        -0.235634             -0.088134   \n5473594      -0.665006        -0.663004             -0.509305   \n...                ...              ...                   ...   \n3007592      -0.665006        -0.696823             -0.583488   \n6771053      -0.665006        -0.696823             -0.583488   \n2842438       0.609177        -0.083400             -0.535628   \n5876236      -0.665006         0.013928              0.758992   \n2162949       0.609177         0.077749             -0.001986   \n\n         Avg Bwd Segment Size  Fwd Avg Bytes/Bulk  Fwd Avg Packets/Bulk  \\\n6300475             -0.201760                 0.0                   0.0   \n5913184             -0.078187                 0.0                   0.0   \n423760              -0.543963                 0.0                   0.0   \n1616769             -0.138616                 0.0                   0.0   \n5473594             -0.543963                 0.0                   0.0   \n...                       ...                 ...                   ...   \n3007592             -0.543963                 0.0                   0.0   \n6771053             -0.543963                 0.0                   0.0   \n2842438              0.110568                 0.0                   0.0   \n5876236             -0.210813                 0.0                   0.0   \n2162949             -0.019795                 0.0                   0.0   \n\n         Fwd Avg Bulk Rate  Bwd Avg Bytes/Bulk  Bwd Avg Packets/Bulk  \\\n6300475                0.0                 0.0                   0.0   \n5913184                0.0                 0.0                   0.0   \n423760                 0.0                 0.0                   0.0   \n1616769                0.0                 0.0                   0.0   \n5473594                0.0                 0.0                   0.0   \n...                    ...                 ...                   ...   \n3007592                0.0                 0.0                   0.0   \n6771053                0.0                 0.0                   0.0   \n2842438                0.0                 0.0                   0.0   \n5876236                0.0                 0.0                   0.0   \n2162949                0.0                 0.0                   0.0   \n\n         Bwd Avg Bulk Rate  Subflow Fwd Packets  Subflow Fwd Bytes  \\\n6300475                0.0            -0.018775          -0.023878   \n5913184                0.0            -0.017323          -0.013505   \n423760                 0.0            -0.019259          -0.024691   \n1616769                0.0            -0.010548          -0.009007   \n5473594                0.0            -0.018291          -0.024320   \n...                    ...                  ...                ...   \n3007592                0.0            -0.018775          -0.024691   \n6771053                0.0            -0.018775          -0.024691   \n2842438                0.0            -0.018291          -0.024452   \n5876236                0.0            -0.017323          -0.013505   \n2162949                0.0            -0.019259          -0.023722   \n\n         Subflow Bwd Packets  Subflow Bwd Bytes  Init Fwd Win Bytes  \\\n6300475            -0.012927          -0.007616           -0.557987   \n5913184            -0.009483          -0.007278           -0.546362   \n423760             -0.014650          -0.007813           -0.539070   \n1616769             0.011187          -0.005949            0.985021   \n5473594            -0.014650          -0.007813           -0.505516   \n...                      ...                ...                 ...   \n3007592            -0.016372          -0.007813           -0.449663   \n6771053            -0.016372          -0.007813            2.823886   \n2842438            -0.009483          -0.007061           -0.125061   \n5876236            -0.011205          -0.007526           -0.545411   \n2162949            -0.014650          -0.007662           -0.557987   \n\n         Init Bwd Win Bytes  Fwd Act Data Packets  Fwd Seg Size Min  \\\n6300475           -0.430904             -0.017215          0.031772   \n5913184           -0.419995             -0.017215          0.031772   \n423760            -0.410372             -0.017702          0.031772   \n1616769           -0.415930             -0.016240          0.031772   \n5473594           -0.430852             -0.017215          0.031772   \n...                     ...                   ...               ...   \n3007592           -0.430904             -0.017702          0.031772   \n6771053           -0.430904             -0.017702          0.031772   \n2842438           -0.419995             -0.017215          0.031772   \n5876236           -0.419995             -0.017215          0.031772   \n2162949           -0.430904             -0.017702          0.031772   \n\n         Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n6300475    -0.079321   -0.064744   -0.097397   -0.065099  -0.022912 -0.002439   \n5913184    -0.079321   -0.064744   -0.097397   -0.065099  -0.022912 -0.002439   \n423760     -0.079321   -0.064744   -0.097397   -0.065099  -0.022912 -0.002439   \n1616769    -0.057800   -0.039814   -0.049389   -0.046643   0.005244  0.002855   \n5473594    -0.079321   -0.064744   -0.097397   -0.065099  -0.022912 -0.002439   \n...              ...         ...         ...         ...        ...       ...   \n3007592    -0.079321   -0.064744   -0.097397   -0.065099   0.209201 -0.002439   \n6771053    -0.079321   -0.064744   -0.097397   -0.065099  -0.022912 -0.002439   \n2842438    -0.079321   -0.064744   -0.097397   -0.065099  -0.022912 -0.002439   \n5876236    -0.079321   -0.064744   -0.097397   -0.065099  -0.022912 -0.002439   \n2162949    -0.079321   -0.064744   -0.097397   -0.065099  -0.022912 -0.002439   \n\n         Idle Max  Idle Min  ClusterLabels  ClassLabel  \n6300475 -0.010545 -0.087599           3810           0  \n5913184 -0.010545 -0.087599           1445           0  \n423760  -0.010545 -0.087599            420           0  \n1616769  0.001712 -0.015847             -1           0  \n5473594 -0.010545 -0.087599           2178           0  \n...           ...       ...            ...         ...  \n3007592  0.087033  0.871862           1848           3  \n6771053 -0.010545 -0.087599           1649           0  \n2842438 -0.010545 -0.087599            750           3  \n5876236 -0.010545 -0.087599           1435           0  \n2162949 -0.010545 -0.087599             -1           0  \n\n[90599 rows x 79 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Protocol</th>\n      <th>Flow Duration</th>\n      <th>Total Fwd Packets</th>\n      <th>Total Backward Packets</th>\n      <th>Fwd Packets Length Total</th>\n      <th>Bwd Packets Length Total</th>\n      <th>Fwd Packet Length Max</th>\n      <th>Fwd Packet Length Min</th>\n      <th>Fwd Packet Length Mean</th>\n      <th>Fwd Packet Length Std</th>\n      <th>Bwd Packet Length Max</th>\n      <th>Bwd Packet Length Min</th>\n      <th>Bwd Packet Length Mean</th>\n      <th>Bwd Packet Length Std</th>\n      <th>Flow Bytes/s</th>\n      <th>Flow Packets/s</th>\n      <th>Flow IAT Mean</th>\n      <th>Flow IAT Std</th>\n      <th>Flow IAT Max</th>\n      <th>Flow IAT Min</th>\n      <th>Fwd IAT Total</th>\n      <th>Fwd IAT Mean</th>\n      <th>Fwd IAT Std</th>\n      <th>Fwd IAT Max</th>\n      <th>Fwd IAT Min</th>\n      <th>Bwd IAT Total</th>\n      <th>Bwd IAT Mean</th>\n      <th>Bwd IAT Std</th>\n      <th>Bwd IAT Max</th>\n      <th>Bwd IAT Min</th>\n      <th>Fwd PSH Flags</th>\n      <th>Bwd PSH Flags</th>\n      <th>Fwd URG Flags</th>\n      <th>Bwd URG Flags</th>\n      <th>Fwd Header Length</th>\n      <th>Bwd Header Length</th>\n      <th>Fwd Packets/s</th>\n      <th>Bwd Packets/s</th>\n      <th>Packet Length Min</th>\n      <th>Packet Length Max</th>\n      <th>Packet Length Mean</th>\n      <th>Packet Length Std</th>\n      <th>Packet Length Variance</th>\n      <th>FIN Flag Count</th>\n      <th>SYN Flag Count</th>\n      <th>RST Flag Count</th>\n      <th>PSH Flag Count</th>\n      <th>ACK Flag Count</th>\n      <th>URG Flag Count</th>\n      <th>CWE Flag Count</th>\n      <th>ECE Flag Count</th>\n      <th>Down/Up Ratio</th>\n      <th>Avg Packet Size</th>\n      <th>Avg Fwd Segment Size</th>\n      <th>Avg Bwd Segment Size</th>\n      <th>Fwd Avg Bytes/Bulk</th>\n      <th>Fwd Avg Packets/Bulk</th>\n      <th>Fwd Avg Bulk Rate</th>\n      <th>Bwd Avg Bytes/Bulk</th>\n      <th>Bwd Avg Packets/Bulk</th>\n      <th>Bwd Avg Bulk Rate</th>\n      <th>Subflow Fwd Packets</th>\n      <th>Subflow Fwd Bytes</th>\n      <th>Subflow Bwd Packets</th>\n      <th>Subflow Bwd Bytes</th>\n      <th>Init Fwd Win Bytes</th>\n      <th>Init Bwd Win Bytes</th>\n      <th>Fwd Act Data Packets</th>\n      <th>Fwd Seg Size Min</th>\n      <th>Active Mean</th>\n      <th>Active Std</th>\n      <th>Active Max</th>\n      <th>Active Min</th>\n      <th>Idle Mean</th>\n      <th>Idle Std</th>\n      <th>Idle Max</th>\n      <th>Idle Min</th>\n      <th>ClusterLabels</th>\n      <th>ClassLabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6300475</th>\n      <td>1.676793</td>\n      <td>-0.024155</td>\n      <td>-0.018775</td>\n      <td>-0.012927</td>\n      <td>-0.023878</td>\n      <td>-0.007616</td>\n      <td>-0.519466</td>\n      <td>0.110412</td>\n      <td>-0.339401</td>\n      <td>-0.543296</td>\n      <td>-0.407501</td>\n      <td>1.810705</td>\n      <td>-0.201760</td>\n      <td>-0.501630</td>\n      <td>-0.044793</td>\n      <td>-0.104969</td>\n      <td>-0.015411</td>\n      <td>-0.005265</td>\n      <td>-0.011938</td>\n      <td>-0.002767</td>\n      <td>-0.023239</td>\n      <td>-0.017209</td>\n      <td>-0.005652</td>\n      <td>-0.011422</td>\n      <td>-0.002981</td>\n      <td>-0.334857</td>\n      <td>-0.200174</td>\n      <td>-0.262981</td>\n      <td>-0.275231</td>\n      <td>-0.086333</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004222</td>\n      <td>-0.093281</td>\n      <td>-0.091193</td>\n      <td>0.125578</td>\n      <td>-0.477361</td>\n      <td>-0.340576</td>\n      <td>-0.463334</td>\n      <td>-0.203713</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.475313</td>\n      <td>-0.867342</td>\n      <td>-0.620914</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.473042</td>\n      <td>0.609177</td>\n      <td>-0.310628</td>\n      <td>-0.339401</td>\n      <td>-0.201760</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018775</td>\n      <td>-0.023878</td>\n      <td>-0.012927</td>\n      <td>-0.007616</td>\n      <td>-0.557987</td>\n      <td>-0.430904</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>3810</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5913184</th>\n      <td>-0.568137</td>\n      <td>-0.017002</td>\n      <td>-0.017323</td>\n      <td>-0.009483</td>\n      <td>-0.013505</td>\n      <td>-0.007278</td>\n      <td>1.275878</td>\n      <td>-0.269129</td>\n      <td>0.758992</td>\n      <td>1.634291</td>\n      <td>-0.223685</td>\n      <td>-0.473586</td>\n      <td>-0.078187</td>\n      <td>-0.089415</td>\n      <td>-0.044922</td>\n      <td>-0.105976</td>\n      <td>-0.013454</td>\n      <td>-0.001905</td>\n      <td>-0.006988</td>\n      <td>-0.002767</td>\n      <td>-0.016085</td>\n      <td>-0.013337</td>\n      <td>-0.000905</td>\n      <td>-0.006472</td>\n      <td>-0.003018</td>\n      <td>-0.323544</td>\n      <td>-0.182879</td>\n      <td>-0.239616</td>\n      <td>-0.258876</td>\n      <td>-0.086376</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004232</td>\n      <td>-0.093808</td>\n      <td>-0.094031</td>\n      <td>-0.279262</td>\n      <td>0.185264</td>\n      <td>0.095845</td>\n      <td>0.235656</td>\n      <td>-0.107130</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.475313</td>\n      <td>-0.867342</td>\n      <td>1.610529</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.473042</td>\n      <td>-0.665006</td>\n      <td>0.089143</td>\n      <td>0.758992</td>\n      <td>-0.078187</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.017323</td>\n      <td>-0.013505</td>\n      <td>-0.009483</td>\n      <td>-0.007278</td>\n      <td>-0.546362</td>\n      <td>-0.419995</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>1445</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>423760</th>\n      <td>-0.568137</td>\n      <td>-0.024212</td>\n      <td>-0.019259</td>\n      <td>-0.014650</td>\n      <td>-0.024691</td>\n      <td>-0.007813</td>\n      <td>-0.587215</td>\n      <td>-0.269129</td>\n      <td>-0.583488</td>\n      <td>-0.543296</td>\n      <td>-0.514233</td>\n      <td>-0.473586</td>\n      <td>-0.543963</td>\n      <td>-0.501630</td>\n      <td>-0.044928</td>\n      <td>0.122823</td>\n      <td>-0.015453</td>\n      <td>-0.005312</td>\n      <td>-0.011980</td>\n      <td>-0.002767</td>\n      <td>-0.023295</td>\n      <td>-0.017335</td>\n      <td>-0.005652</td>\n      <td>-0.011464</td>\n      <td>-0.003018</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004223</td>\n      <td>0.026202</td>\n      <td>0.549481</td>\n      <td>-0.279262</td>\n      <td>-0.580564</td>\n      <td>-0.679005</td>\n      <td>-0.600738</td>\n      <td>-0.206392</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.475313</td>\n      <td>-0.867342</td>\n      <td>1.610529</td>\n      <td>5.157202</td>\n      <td>-0.049057</td>\n      <td>-0.473042</td>\n      <td>0.609177</td>\n      <td>-0.696823</td>\n      <td>-0.583488</td>\n      <td>-0.543963</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.019259</td>\n      <td>-0.024691</td>\n      <td>-0.014650</td>\n      <td>-0.007813</td>\n      <td>-0.539070</td>\n      <td>-0.410372</td>\n      <td>-0.017702</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>420</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1616769</th>\n      <td>-0.568137</td>\n      <td>0.156313</td>\n      <td>-0.010548</td>\n      <td>0.011187</td>\n      <td>-0.009007</td>\n      <td>-0.005949</td>\n      <td>0.283557</td>\n      <td>-0.269129</td>\n      <td>-0.088134</td>\n      <td>0.309289</td>\n      <td>0.160043</td>\n      <td>-0.473586</td>\n      <td>-0.138616</td>\n      <td>0.166299</td>\n      <td>-0.044927</td>\n      <td>-0.105991</td>\n      <td>-0.003678</td>\n      <td>0.005398</td>\n      <td>-0.000357</td>\n      <td>-0.002767</td>\n      <td>0.157841</td>\n      <td>0.004902</td>\n      <td>0.005178</td>\n      <td>0.000159</td>\n      <td>-0.003018</td>\n      <td>3.897836</td>\n      <td>1.093564</td>\n      <td>0.642553</td>\n      <td>0.492960</td>\n      <td>-0.086316</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009330</td>\n      <td>0.004261</td>\n      <td>-0.093817</td>\n      <td>-0.094070</td>\n      <td>-0.279262</td>\n      <td>0.071414</td>\n      <td>-0.187852</td>\n      <td>0.066182</td>\n      <td>-0.143281</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.475313</td>\n      <td>1.152947</td>\n      <td>-0.620914</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.473042</td>\n      <td>-0.665006</td>\n      <td>-0.235634</td>\n      <td>-0.088134</td>\n      <td>-0.138616</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.010548</td>\n      <td>-0.009007</td>\n      <td>0.011187</td>\n      <td>-0.005949</td>\n      <td>0.985021</td>\n      <td>-0.415930</td>\n      <td>-0.016240</td>\n      <td>0.031772</td>\n      <td>-0.057800</td>\n      <td>-0.039814</td>\n      <td>-0.049389</td>\n      <td>-0.046643</td>\n      <td>0.005244</td>\n      <td>0.002855</td>\n      <td>0.001712</td>\n      <td>-0.015847</td>\n      <td>-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5473594</th>\n      <td>-0.568137</td>\n      <td>-0.024212</td>\n      <td>-0.018291</td>\n      <td>-0.014650</td>\n      <td>-0.024320</td>\n      <td>-0.007813</td>\n      <td>-0.525444</td>\n      <td>-0.269129</td>\n      <td>-0.509305</td>\n      <td>-0.450089</td>\n      <td>-0.514233</td>\n      <td>-0.473586</td>\n      <td>-0.543963</td>\n      <td>-0.501630</td>\n      <td>-0.043752</td>\n      <td>-0.013365</td>\n      <td>-0.015453</td>\n      <td>-0.005312</td>\n      <td>-0.011979</td>\n      <td>-0.002767</td>\n      <td>-0.023295</td>\n      <td>-0.017334</td>\n      <td>-0.005651</td>\n      <td>-0.011464</td>\n      <td>-0.003018</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004222</td>\n      <td>-0.020939</td>\n      <td>0.036185</td>\n      <td>-0.279262</td>\n      <td>-0.555173</td>\n      <td>-0.649369</td>\n      <td>-0.562935</td>\n      <td>-0.206189</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.475313</td>\n      <td>-0.867342</td>\n      <td>1.610529</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.473042</td>\n      <td>-0.665006</td>\n      <td>-0.663004</td>\n      <td>-0.509305</td>\n      <td>-0.543963</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018291</td>\n      <td>-0.024320</td>\n      <td>-0.014650</td>\n      <td>-0.007813</td>\n      <td>-0.505516</td>\n      <td>-0.430852</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>2178</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3007592</th>\n      <td>-0.568137</td>\n      <td>0.099460</td>\n      <td>-0.018775</td>\n      <td>-0.016372</td>\n      <td>-0.024691</td>\n      <td>-0.007813</td>\n      <td>-0.587215</td>\n      <td>-0.269129</td>\n      <td>-0.583488</td>\n      <td>-0.543296</td>\n      <td>-0.514233</td>\n      <td>-0.473586</td>\n      <td>-0.543963</td>\n      <td>-0.501630</td>\n      <td>-0.044928</td>\n      <td>-0.105994</td>\n      <td>0.258664</td>\n      <td>-0.005312</td>\n      <td>0.080548</td>\n      <td>0.078858</td>\n      <td>0.100304</td>\n      <td>0.256765</td>\n      <td>-0.005652</td>\n      <td>0.081064</td>\n      <td>0.078606</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004221</td>\n      <td>-0.093819</td>\n      <td>-0.094077</td>\n      <td>-0.279262</td>\n      <td>-0.580564</td>\n      <td>-0.679005</td>\n      <td>-0.600738</td>\n      <td>-0.206392</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.475313</td>\n      <td>-0.867342</td>\n      <td>1.610529</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.473042</td>\n      <td>-0.665006</td>\n      <td>-0.696823</td>\n      <td>-0.583488</td>\n      <td>-0.543963</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018775</td>\n      <td>-0.024691</td>\n      <td>-0.016372</td>\n      <td>-0.007813</td>\n      <td>-0.449663</td>\n      <td>-0.430904</td>\n      <td>-0.017702</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>0.209201</td>\n      <td>-0.002439</td>\n      <td>0.087033</td>\n      <td>0.871862</td>\n      <td>1848</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6771053</th>\n      <td>-0.568137</td>\n      <td>-0.023580</td>\n      <td>-0.018775</td>\n      <td>-0.016372</td>\n      <td>-0.024691</td>\n      <td>-0.007813</td>\n      <td>-0.587215</td>\n      <td>-0.269129</td>\n      <td>-0.583488</td>\n      <td>-0.543296</td>\n      <td>-0.514233</td>\n      <td>-0.473586</td>\n      <td>-0.543963</td>\n      <td>-0.501630</td>\n      <td>-0.044928</td>\n      <td>-0.105948</td>\n      <td>-0.014052</td>\n      <td>-0.005312</td>\n      <td>-0.011507</td>\n      <td>-0.002350</td>\n      <td>-0.022663</td>\n      <td>-0.015934</td>\n      <td>-0.005652</td>\n      <td>-0.010991</td>\n      <td>-0.002601</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004221</td>\n      <td>-0.093771</td>\n      <td>-0.094077</td>\n      <td>-0.279262</td>\n      <td>-0.580564</td>\n      <td>-0.679005</td>\n      <td>-0.600738</td>\n      <td>-0.206392</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.475313</td>\n      <td>-0.867342</td>\n      <td>1.610529</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.473042</td>\n      <td>-0.665006</td>\n      <td>-0.696823</td>\n      <td>-0.583488</td>\n      <td>-0.543963</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018775</td>\n      <td>-0.024691</td>\n      <td>-0.016372</td>\n      <td>-0.007813</td>\n      <td>2.823886</td>\n      <td>-0.430904</td>\n      <td>-0.017702</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>1649</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2842438</th>\n      <td>-0.568137</td>\n      <td>-0.024178</td>\n      <td>-0.018291</td>\n      <td>-0.009483</td>\n      <td>-0.024452</td>\n      <td>-0.007061</td>\n      <td>-0.547363</td>\n      <td>-0.269129</td>\n      <td>-0.535628</td>\n      <td>-0.483162</td>\n      <td>0.302353</td>\n      <td>-0.473586</td>\n      <td>0.110568</td>\n      <td>0.501685</td>\n      <td>-0.044235</td>\n      <td>-0.102984</td>\n      <td>-0.015441</td>\n      <td>-0.005292</td>\n      <td>-0.011955</td>\n      <td>-0.002767</td>\n      <td>-0.023295</td>\n      <td>-0.017334</td>\n      <td>-0.005651</td>\n      <td>-0.011463</td>\n      <td>-0.003018</td>\n      <td>-0.334081</td>\n      <td>-0.199041</td>\n      <td>-0.260307</td>\n      <td>-0.273627</td>\n      <td>-0.086422</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004228</td>\n      <td>-0.092466</td>\n      <td>-0.084401</td>\n      <td>-0.279262</td>\n      <td>0.209017</td>\n      <td>-0.091056</td>\n      <td>0.326065</td>\n      <td>-0.084512</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>2.103879</td>\n      <td>1.152947</td>\n      <td>-0.620914</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>2.113978</td>\n      <td>0.609177</td>\n      <td>-0.083400</td>\n      <td>-0.535628</td>\n      <td>0.110568</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018291</td>\n      <td>-0.024452</td>\n      <td>-0.009483</td>\n      <td>-0.007061</td>\n      <td>-0.125061</td>\n      <td>-0.419995</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>750</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5876236</th>\n      <td>-0.568137</td>\n      <td>-0.017600</td>\n      <td>-0.017323</td>\n      <td>-0.011205</td>\n      <td>-0.013505</td>\n      <td>-0.007526</td>\n      <td>1.275878</td>\n      <td>-0.269129</td>\n      <td>0.758992</td>\n      <td>1.634291</td>\n      <td>-0.202508</td>\n      <td>-0.473586</td>\n      <td>-0.210813</td>\n      <td>-0.059370</td>\n      <td>-0.044923</td>\n      <td>-0.105977</td>\n      <td>-0.013358</td>\n      <td>-0.001728</td>\n      <td>-0.007106</td>\n      <td>-0.002767</td>\n      <td>-0.016683</td>\n      <td>-0.013669</td>\n      <td>-0.000923</td>\n      <td>-0.006590</td>\n      <td>-0.003018</td>\n      <td>-0.332980</td>\n      <td>-0.195898</td>\n      <td>-0.254990</td>\n      <td>-0.271281</td>\n      <td>-0.086365</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004229</td>\n      <td>-0.093807</td>\n      <td>-0.094040</td>\n      <td>-0.279262</td>\n      <td>0.185264</td>\n      <td>0.013044</td>\n      <td>0.272796</td>\n      <td>-0.098119</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.475313</td>\n      <td>-0.867342</td>\n      <td>1.610529</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.473042</td>\n      <td>-0.665006</td>\n      <td>0.013928</td>\n      <td>0.758992</td>\n      <td>-0.210813</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.017323</td>\n      <td>-0.013505</td>\n      <td>-0.011205</td>\n      <td>-0.007526</td>\n      <td>-0.545411</td>\n      <td>-0.419995</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>1435</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2162949</th>\n      <td>1.676793</td>\n      <td>-0.024212</td>\n      <td>-0.019259</td>\n      <td>-0.014650</td>\n      <td>-0.023722</td>\n      <td>-0.007662</td>\n      <td>-0.425813</td>\n      <td>0.635072</td>\n      <td>-0.001986</td>\n      <td>-0.543296</td>\n      <td>-0.350747</td>\n      <td>3.025367</td>\n      <td>-0.019795</td>\n      <td>-0.501630</td>\n      <td>-0.034537</td>\n      <td>-0.059679</td>\n      <td>-0.015452</td>\n      <td>-0.005312</td>\n      <td>-0.011979</td>\n      <td>-0.002767</td>\n      <td>-0.023295</td>\n      <td>-0.017335</td>\n      <td>-0.005652</td>\n      <td>-0.011464</td>\n      <td>-0.003018</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004222</td>\n      <td>-0.069526</td>\n      <td>0.036185</td>\n      <td>0.685211</td>\n      <td>-0.422484</td>\n      <td>-0.113363</td>\n      <td>-0.424415</td>\n      <td>-0.201981</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.475313</td>\n      <td>-0.867342</td>\n      <td>-0.620914</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.473042</td>\n      <td>0.609177</td>\n      <td>0.077749</td>\n      <td>-0.001986</td>\n      <td>-0.019795</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.019259</td>\n      <td>-0.023722</td>\n      <td>-0.014650</td>\n      <td>-0.007662</td>\n      <td>-0.557987</td>\n      <td>-0.430904</td>\n      <td>-0.017702</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>-1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>90599 rows  79 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_major"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def sampling(df):\n",
    "    name = df.name\n",
    "    frac = 1.0\n",
    "    return df.sample(frac=frac)\n",
    "result = df_major.groupby('ClusterLabels', group_keys=False).apply(sampling)\n",
    "result = result.drop([\"ClusterLabels\"], axis=1)\n",
    "result = result.append(df_minor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0    71634\n3    12505\n4     3997\n1     1413\n2     1050\n5     1018\n7       36\n6       23\nName: ClassLabel, dtype: int64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['ClassLabel'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "result.to_csv('./ids_data/CIC_Collection_clean_sample.csv', index=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sampling from improved data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Improved Sampled Shape: (91676, 58)\n"
     ]
    }
   ],
   "source": [
    "df_improved_sample1 = df_improved.sample(frac=0.01, random_state=1)\n",
    "print(f\"DF Improved Sampled Shape: {df_improved_sample1.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Minors are 5: Infiltration, 7: Webattack, 6: Portscan\n",
    "# Keep the minor size and sampling from the remaining major classes\n",
    "dfi_minor = df_improved_sample1[(df_improved_sample1['ClassLabel'] == 5) | \\\n",
    "                      (df_improved_sample1['ClassLabel'] == 7) | (df_improved_sample1['ClassLabel'] == 6)]\n",
    "dfi_major = df_improved_sample1.drop(dfi_minor.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(90599, 57)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_im = dfi_major.drop(['ClassLabel'], axis=1)\n",
    "y_im = dfi_major.iloc[:, -1].values.reshape(-1, 1)\n",
    "y_im = np.ravel(y_im)\n",
    "X_im.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start clusturing\n",
      "-1       27554\n",
      " 1354     2905\n",
      " 2916     1312\n",
      " 897       710\n",
      " 2888      618\n",
      "         ...  \n",
      " 2951        5\n",
      " 2017        5\n",
      " 204         5\n",
      " 3070        5\n",
      " 3739        5\n",
      "Name: ClusterLabels, Length: 3856, dtype: int64\n",
      "done clustering \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Sampling the improved dataset\n",
    "# Use HDBSCAN to Cluster the data samples\n",
    "print('start clusturing')\n",
    "clusterer = hdbscan.HDBSCAN()\n",
    "clusterer.fit(X_im)\n",
    "cluster_labels = clusterer.labels_\n",
    "dfi_major[\"ClusterLabels\"] = cluster_labels\n",
    "print(dfi_major[\"ClusterLabels\"].value_counts())\n",
    "print(\"done clustering \\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "cols_im = list(dfi_major)\n",
    "# with 2 layer of metadata removed it is 58, without it is 69\n",
    "cols_im.insert(58, cols_im.pop(cols_im.index('ClassLabel')))\n",
    "dfi_major = dfi_major.loc[:, cols_im]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "result_im = dfi_major.groupby('ClusterLabels', group_keys=False).apply(sampling)\n",
    "result_im = result_im.drop([\"ClusterLabels\"], axis=1)\n",
    "result_im = result_im.append(dfi_minor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "0    71634\n3    12505\n4     3997\n1     1413\n2     1050\n5     1018\n7       36\n6       23\nName: ClassLabel, dtype: int64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_im['ClassLabel'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "result_im.to_csv('./ids_data/CIC_Collection_improved_sample.csv', index=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split train set and test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "df_clean_sample = pd.read_csv('./ids_data/CIC_Collection_clean_sample.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "X = df_clean_sample.drop(['ClassLabel'],axis=1).values\n",
    "y = df_clean_sample.iloc[:, -1].values.reshape(-1,1)\n",
    "y = np.ravel(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0,stratify = y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering\n",
    "### Feature selection by genetic algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [42], line 15\u001B[0m\n\u001B[1;32m      1\u001B[0m clf \u001B[38;5;241m=\u001B[39m SVC(gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m evolved_estimator \u001B[38;5;241m=\u001B[39m GAFeatureSelectionCV(\n\u001B[1;32m      4\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mclf,\n\u001B[1;32m      5\u001B[0m     cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m     elitism \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     13\u001B[0m )\n\u001B[0;32m---> 15\u001B[0m \u001B[43mevolved_estimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m features \u001B[38;5;241m=\u001B[39m evolved_estimator\u001B[38;5;241m.\u001B[39mbest_features_\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/site-packages/sklearn_genetic/genetic_search.py:1175\u001B[0m, in \u001B[0;36mGAFeatureSelectionCV.fit\u001B[0;34m(self, X, y, callbacks)\u001B[0m\n\u001B[1;32m   1172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_register()\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;66;03m# Optimization routine from the selected evolutionary algorithm\u001B[39;00m\n\u001B[0;32m-> 1175\u001B[0m pop, log, n_gen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_select_algorithm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1176\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhof\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_hof\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# Update the _n_iterations value as the algorithm could stop earlier due a callback\u001B[39;00m\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_iterations \u001B[38;5;241m=\u001B[39m n_gen\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/site-packages/sklearn_genetic/genetic_search.py:1254\u001B[0m, in \u001B[0;36mGAFeatureSelectionCV._select_algorithm\u001B[0;34m(self, pop, stats, hof)\u001B[0m\n\u001B[1;32m   1239\u001B[0m     pop, log, gen \u001B[38;5;241m=\u001B[39m eaSimple(\n\u001B[1;32m   1240\u001B[0m         pop,\n\u001B[1;32m   1241\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoolbox,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1249\u001B[0m         estimator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1250\u001B[0m     )\n\u001B[1;32m   1252\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgorithm \u001B[38;5;241m==\u001B[39m Algorithms\u001B[38;5;241m.\u001B[39meaMuPlusLambda\u001B[38;5;241m.\u001B[39mvalue:\n\u001B[0;32m-> 1254\u001B[0m     pop, log, gen \u001B[38;5;241m=\u001B[39m \u001B[43meaMuPlusLambda\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1255\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1256\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoolbox\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1257\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpopulation_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1258\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlambda_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpopulation_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1259\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcxpb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcrossover_adapter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1260\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmutpb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmutation_adapter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1262\u001B[0m \u001B[43m        \u001B[49m\u001B[43mngen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1263\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhalloffame\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhof\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1264\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1265\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1266\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1267\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1269\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgorithm \u001B[38;5;241m==\u001B[39m Algorithms\u001B[38;5;241m.\u001B[39meaMuCommaLambda\u001B[38;5;241m.\u001B[39mvalue:\n\u001B[1;32m   1270\u001B[0m     pop, log, gen \u001B[38;5;241m=\u001B[39m eaMuCommaLambda(\n\u001B[1;32m   1271\u001B[0m         pop,\n\u001B[1;32m   1272\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoolbox,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1282\u001B[0m         estimator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1283\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/site-packages/sklearn_genetic/algorithms.py:278\u001B[0m, in \u001B[0;36meaMuPlusLambda\u001B[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, stats, halloffame, callbacks, verbose, estimator)\u001B[0m\n\u001B[1;32m    276\u001B[0m invalid_ind \u001B[38;5;241m=\u001B[39m [ind \u001B[38;5;28;01mfor\u001B[39;00m ind \u001B[38;5;129;01min\u001B[39;00m population \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ind\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalid]\n\u001B[1;32m    277\u001B[0m fitnesses \u001B[38;5;241m=\u001B[39m toolbox\u001B[38;5;241m.\u001B[39mmap(toolbox\u001B[38;5;241m.\u001B[39mevaluate, invalid_ind)\n\u001B[0;32m--> 278\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ind, fit \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(invalid_ind, fitnesses):\n\u001B[1;32m    279\u001B[0m     ind\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;241m=\u001B[39m fit\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m halloffame \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/site-packages/sklearn_genetic/genetic_search.py:1075\u001B[0m, in \u001B[0;36mGAFeatureSelectionCV.evaluate\u001B[0;34m(self, individual)\u001B[0m\n\u001B[1;32m   1072\u001B[0m n_selected_features \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(individual)\n\u001B[1;32m   1074\u001B[0m \u001B[38;5;66;03m# Compute the cv-metrics using only the selected features\u001B[39;00m\n\u001B[0;32m-> 1075\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbool_individual\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscoring\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1087\u001B[0m cv_scores \u001B[38;5;241m=\u001B[39m cv_results[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefit_metric\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1088\u001B[0m score \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(cv_scores)\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[1;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/site-packages/joblib/parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/site-packages/joblib/parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/concurrent/futures/_base.py:453\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/anaconda3/envs/Hybrid_Intrusion_Detection_System/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "\n",
    "evolved_estimator = GAFeatureSelectionCV(\n",
    "    estimator=clf,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    population_size = 40,\n",
    "    generations = 15,\n",
    "    n_jobs = -1,\n",
    "    verbose = True,\n",
    "    keep_top_k = 2,\n",
    "    elitism = True,\n",
    ")\n",
    "\n",
    "evolved_estimator.fit(X, y)\n",
    "features = evolved_estimator.best_features_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Original X Shape: {X.shape}\")\n",
    "\n",
    "X_best_features = X[:, features]\n",
    "\n",
    "print(f\"Best Features X Shape: {X_best_features.shape}\")\n",
    "\n",
    "pd.DataFrame(X_best_features).to_csv('./ids_data/X_best_features.csv', index=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature selection by Fast Correlation Based Filter (FCBF)\n",
    "GitHub repo: https://github.com/SantiagoEG/FCBF_module"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from FCBF_module import FCBF, FCBFK, FCBFiP, get_i\n",
    "fcbf = FCBFK(k = 20)\n",
    "X_bf = pd.read_csv('./ids_data/X_best_features.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_bbf = fcbf.fit_transform(X_bf)\n",
    "X_bbf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Re-split train & test sets after feature selection from genetic algorithm\n",
    "## and fast correlation based filter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bbf,y, train_size = 0.8, test_size = 0.2, random_state = 0,stratify = y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split train and test sets for improved dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Synthetic Minority Oversampling Technique (SMOTE) to solve class imbalance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(n_jobs=-1,sampling_strategy='not majority')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Intrusion Detection System Model Training - For Clean Data\n",
    "### Training 3 base learners: Random forest, XGBoost, Decision Tree (Isolation forest for anomaly)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Applying Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(random_state=7)\n",
    "randomforest.fit(X_train, y_train)\n",
    "rf_score = randomforest.score(X_test, y_test)\n",
    "y_predict = randomforest.predict(X_test)\n",
    "y_actual = y_test\n",
    "print('Accuracy of RF: '+ str(rf_score))\n",
    "precision,recall, fscore, none= precision_recall_fscore_support(y_actual, y_predict, average='weighted')\n",
    "print('Precision of RF: '+(str(precision)))\n",
    "print('Recall of RF: '+(str(recall)))\n",
    "print('F1-score of RF: '+(str(fscore))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(7,5=7))\n",
    "sns.heatmap(cm, annot=True,linewidth=0.5, cmap=\"YlGnBu\",fmt=\".0f\", ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_actual\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Applying XG BOOST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier(n_estimators = 10)\n",
    "xgboost.fit(X_train,y_train)\n",
    "xgboost_score=xg.score(X_test,y_test)\n",
    "y_predict=xgboost.predict(X_test)\n",
    "y_actual=y_test\n",
    "print('Accuracy of XGBoost: '+ str(xgboost_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_actual, y_predict, average='weighted')\n",
    "print('Precision of XGBoost: '+(str(precision)))\n",
    "print('Recall of XGBoost: '+(str(recall)))\n",
    "print('F1-score of XGBoost: '+(str(fscore)))\n",
    "print(classification_report(y_actual,y_predict))\n",
    "cm=confusion_matrix(y_actual,y_predict)\n",
    "f,ax=plt.subplots(figsize=(7,7))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5, cmap=\"YlGnBu\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_actual\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "def ids_stacked(X_train, X_test, y_train, y_test):\n",
    "    clf1 = RandomForestClassifier(random_state=7)\n",
    "    clf2 = xgb.XGBClassifier(n_estimators = 10)\n",
    "    clf3 = DecisionTreeClassifier(random_state = 7)\n",
    "\n",
    "    eclf1 = VotingClassifier(estimators=[\n",
    "        ('rf', clf1), ('xgb', clf2), ('dt', clf3)], voting='hard')\n",
    "    eclf1.fit(X_train,y_train)\n",
    "    eclf1_score = eclf1.score(X_test, y_test)\n",
    "    y_predict = eclf1.predict(X_test)\n",
    "    y_actual = y\n",
    "    print(f'Accuracy of Stacked Classifiers: {eclf1_score}')\n",
    "    precision, recall, fscore, none= precision_recall_fscore_support(y_actual, y_predict, average='weighted')\n",
    "    print(f'Precision of Stacked Classifiers: {precision}')\n",
    "    print(f'Recall of Stacked Classifiers: {recall}')\n",
    "    print(f'F1-score of Stacked Classifiers: {fscore}')\n",
    "    print(classification_report(y_actual,y_predict))\n",
    "    cm=confusion_matrix(y_actual,y_predict)\n",
    "    f,ax=plt.subplots(figsize=(7,7))\n",
    "    sns.heatmap(cm,annot=True,linewidth=0.5, cmap=\"YlGnBu\",fmt=\".0f\",ax=ax)\n",
    "    plt.xlabel(\"y_pred\")\n",
    "    plt.ylabel(\"y_actual\")\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
