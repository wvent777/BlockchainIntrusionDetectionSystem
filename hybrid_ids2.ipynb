{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HYBRID INTRUSION DETECTION SYSTEM (PLACEHOLDER)\n",
    "\n",
    "This is the code for the paper \" \"\n",
    "\n",
    "Author: William S. Ventura (w.stephan.ventura@gmail.com)\n",
    "Organization: Whiting School of Engineering, Johns Hopkins University"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IMPORT LIBRARIES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 05:10:28.524698: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn_genetic import GAFeatureSelectionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn_genetic.plots import plot_fitness_evolution\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import hdbscan\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading in the CIC_Collection Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The CIC Collection Dataset is a combination of CIC-IDS2017, CIC-DoS2017, CSE-CIC-IDS2018 and CIC-DDoS2019. Publicly available on Kaggle @ https://www.kaggle.com/code/dhoogla/cic-collection-00-clean-up\n",
    "\n",
    "Note: The cleaned up version of this collection has removed contaminated features found in the CIC datasets and other NIDS datasets which have equal blind predictive power across all available attack classes, despite having had access to only one attack class during training.\n",
    "The features which contaminate the CIC collection dataset in the aforementioned way are in order of severity:\n",
    "\n",
    "    PSH Flag Count, ECE Flag Count, RST Flag Count, ACK Flag Count\n",
    "    Fwd Packet Length Min\n",
    "    Bwd Packet Length Min\n",
    "    Packet Length Min\n",
    "    Protocol\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: At the start of this project the original cic-collection was used, it was later modified to use the cleaned up version, both .parquet files are available in the \"ids_data\" folder\n",
    "\n",
    "Note: Due to the massive size of the dataset and hardware limitations, a sampled subset of CIC_Collection is used. The subsets are in the \"ids_data\" folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_parquet(\"./ids_data/cic-collection.parquet\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(9167581, 79)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Improving the CIC Collection\n",
    "###  1.Removing contaminating features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Protocol', 'Flow Duration', 'Total Fwd Packets',\n       'Total Backward Packets', 'Fwd Packets Length Total',\n       'Bwd Packets Length Total', 'Fwd Packet Length Max',\n       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n       'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n       'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n       'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n       'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate',\n       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n       'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes',\n       'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n       'Idle Min', 'Label', 'ClassLabel'],\n      dtype='object')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(9167581, 70)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['PSH Flag Count', 'ECE Flag Count', 'RST Flag Count', 'ACK Flag Count', 'Fwd Packet Length Min', 'Bwd Packet Length Min', 'Packet Length Min', 'Protocol', 'Down/Up Ratio'], axis=0)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Removing features with no separating power\n",
    "\n",
    "For the CIC collection, 11 features with 0 predictive power have been identified based on the findings in \"Discovering Non-Metadata Contaminant Features in Intrusion Detection Datasets\"\n",
    "\n",
    "Link:\n",
    "https://www.researchgate.net/publication/363265363_Discovering_Non-Metadata_Contaminant_Features_in_Intrusion_Detection_Datasets?channel=doi&linkId=6314afa85eed5e4bd1478531&showFulltext=true"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['Bwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd PSH Flags', 'Bwd URG Flags', 'CWE Flag Count', 'FIN Flag Count', 'Fwd Avg Bulk Rate', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd URG Flags'])\n",
    "#df.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df.to_parquet('./ids_data/cic-collection-clean.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9167581 entries, 0 to 9167580\n",
      "Data columns (total 70 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   Flow Duration             int64  \n",
      " 1   Total Fwd Packets         int32  \n",
      " 2   Total Backward Packets    int32  \n",
      " 3   Fwd Packets Length Total  float64\n",
      " 4   Bwd Packets Length Total  float64\n",
      " 5   Fwd Packet Length Max     float64\n",
      " 6   Fwd Packet Length Mean    float32\n",
      " 7   Fwd Packet Length Std     float32\n",
      " 8   Bwd Packet Length Max     float64\n",
      " 9   Bwd Packet Length Mean    float32\n",
      " 10  Bwd Packet Length Std     float32\n",
      " 11  Flow Bytes/s              float64\n",
      " 12  Flow Packets/s            float64\n",
      " 13  Flow IAT Mean             float32\n",
      " 14  Flow IAT Std              float32\n",
      " 15  Flow IAT Max              float64\n",
      " 16  Flow IAT Min              float64\n",
      " 17  Fwd IAT Total             float64\n",
      " 18  Fwd IAT Mean              float32\n",
      " 19  Fwd IAT Std               float32\n",
      " 20  Fwd IAT Max               float64\n",
      " 21  Fwd IAT Min               float64\n",
      " 22  Bwd IAT Total             float64\n",
      " 23  Bwd IAT Mean              float32\n",
      " 24  Bwd IAT Std               float32\n",
      " 25  Bwd IAT Max               float64\n",
      " 26  Bwd IAT Min               float64\n",
      " 27  Fwd PSH Flags             int8   \n",
      " 28  Bwd PSH Flags             int8   \n",
      " 29  Fwd URG Flags             int8   \n",
      " 30  Bwd URG Flags             int8   \n",
      " 31  Fwd Header Length         int64  \n",
      " 32  Bwd Header Length         int64  \n",
      " 33  Fwd Packets/s             float32\n",
      " 34  Bwd Packets/s             float32\n",
      " 35  Packet Length Max         float64\n",
      " 36  Packet Length Mean        float32\n",
      " 37  Packet Length Std         float32\n",
      " 38  Packet Length Variance    float32\n",
      " 39  FIN Flag Count            int8   \n",
      " 40  SYN Flag Count            int8   \n",
      " 41  URG Flag Count            int8   \n",
      " 42  CWE Flag Count            int8   \n",
      " 43  Avg Packet Size           float32\n",
      " 44  Avg Fwd Segment Size      float32\n",
      " 45  Avg Bwd Segment Size      float32\n",
      " 46  Fwd Avg Bytes/Bulk        int8   \n",
      " 47  Fwd Avg Packets/Bulk      int8   \n",
      " 48  Fwd Avg Bulk Rate         int8   \n",
      " 49  Bwd Avg Bytes/Bulk        int8   \n",
      " 50  Bwd Avg Packets/Bulk      int8   \n",
      " 51  Bwd Avg Bulk Rate         int8   \n",
      " 52  Subflow Fwd Packets       int32  \n",
      " 53  Subflow Fwd Bytes         int32  \n",
      " 54  Subflow Bwd Packets       int32  \n",
      " 55  Subflow Bwd Bytes         int32  \n",
      " 56  Init Fwd Win Bytes        int32  \n",
      " 57  Init Bwd Win Bytes        int32  \n",
      " 58  Fwd Act Data Packets      int32  \n",
      " 59  Fwd Seg Size Min          int32  \n",
      " 60  Active Mean               float32\n",
      " 61  Active Std                float32\n",
      " 62  Active Max                float64\n",
      " 63  Active Min                float64\n",
      " 64  Idle Mean                 float32\n",
      " 65  Idle Std                  float32\n",
      " 66  Idle Max                  float64\n",
      " 67  Idle Min                  float64\n",
      " 68  Label                     object \n",
      " 69  ClassLabel                object \n",
      "dtypes: float32(22), float64(19), int32(10), int64(3), int8(14), object(2)\n",
      "memory usage: 2.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Drop unnecessary columns (Extra Label Column)\n",
    "df.drop(columns=[\"Label\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Z-Score Normalization\n",
    "features = df.dtypes[df.dtypes != 'object'].index\n",
    "df[features] = df[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# Fill nan values with 0\n",
    "df = df.fillna(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0    7186189\n3    1234729\n4     397344\n1     145968\n2     103244\n5      94857\n7       2995\n6       2255\nName: ClassLabel, dtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding labels\n",
    "labelencoder = LabelEncoder()\n",
    "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])\n",
    "df.ClassLabel.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(9167581, 69)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Sampling\n",
    "Since the data is too large, a small subset will be generated to train the model using HDBSCAN clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Sampled Shape: (91676, 69)\n"
     ]
    }
   ],
   "source": [
    "# Can Adjust Sample Size, but HDBSCAN was taking too long with the original data set\n",
    "# Going to resample twice\n",
    "df_sample1 = df.sample(frac=0.01, random_state=1)\n",
    "print(f\"DF Sampled Shape: {df_sample1.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Minors are 5: Infiltration, 7: Webattack, 6: Portscan\n",
    "# Keep the minor size and sampling from the remaining major classes\n",
    "df_minor = df_sample1[(df_sample1['ClassLabel'] == 5) | \\\n",
    "                      (df_sample1['ClassLabel'] == 7) | (df_sample1['ClassLabel'] == 6)]\n",
    "df_major = df_sample1.drop(df_minor.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(90599, 68)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_major.drop(['ClassLabel'], axis=1)\n",
    "y = df_major.iloc[:, -1].values.reshape(-1, 1)\n",
    "y = np.ravel(y)\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start clusturing\n",
      "-1       27569\n",
      " 1380     2905\n",
      " 2941     1311\n",
      " 925       710\n",
      " 2892      618\n",
      "         ...  \n",
      " 3672        5\n",
      " 1423        5\n",
      " 2322        5\n",
      " 2178        5\n",
      " 3738        5\n",
      "Name: ClusterLabels, Length: 3854, dtype: int64\n",
      "done clustering \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use HDBSCAN to Cluster the data samples\n",
    "print('start clusturing')\n",
    "clusterer = hdbscan.HDBSCAN()\n",
    "clusterer.fit(X)\n",
    "cluster_labels = clusterer.labels_\n",
    "df_major[\"ClusterLabels\"] = cluster_labels\n",
    "print(df_major[\"ClusterLabels\"].value_counts())\n",
    "print(\"done clustering \\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "cols = list(df_major)\n",
    "# with 2 layer of metadata removed it is 58, without it is 69\n",
    "cols.insert(69, cols.pop(cols.index('ClassLabel')))\n",
    "df_major = df_major.loc[:, cols]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "         Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n6300475      -0.024155          -0.018775               -0.012927   \n5913184      -0.017002          -0.017323               -0.009483   \n423760       -0.024212          -0.019259               -0.014650   \n1616769       0.156313          -0.010548                0.011187   \n5473594      -0.024212          -0.018291               -0.014650   \n...                ...                ...                     ...   \n3007592       0.099460          -0.018775               -0.016372   \n6771053      -0.023580          -0.018775               -0.016372   \n2842438      -0.024178          -0.018291               -0.009483   \n5876236      -0.017600          -0.017323               -0.011205   \n2162949      -0.024212          -0.019259               -0.014650   \n\n         Fwd Packets Length Total  Bwd Packets Length Total  \\\n6300475                 -0.023878                 -0.007616   \n5913184                 -0.013505                 -0.007278   \n423760                  -0.024691                 -0.007813   \n1616769                 -0.009007                 -0.005949   \n5473594                 -0.024320                 -0.007813   \n...                           ...                       ...   \n3007592                 -0.024691                 -0.007813   \n6771053                 -0.024691                 -0.007813   \n2842438                 -0.024452                 -0.007061   \n5876236                 -0.013505                 -0.007526   \n2162949                 -0.023722                 -0.007662   \n\n         Fwd Packet Length Max  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n6300475              -0.519466               -0.339401              -0.543296   \n5913184               1.275878                0.758992               1.634291   \n423760               -0.587215               -0.583488              -0.543296   \n1616769               0.283557               -0.088134               0.309289   \n5473594              -0.525444               -0.509305              -0.450089   \n...                        ...                     ...                    ...   \n3007592              -0.587215               -0.583488              -0.543296   \n6771053              -0.587215               -0.583488              -0.543296   \n2842438              -0.547363               -0.535628              -0.483162   \n5876236               1.275878                0.758992               1.634291   \n2162949              -0.425813               -0.001986              -0.543296   \n\n         Bwd Packet Length Max  Bwd Packet Length Mean  Bwd Packet Length Std  \\\n6300475              -0.407501               -0.201760              -0.501630   \n5913184              -0.223685               -0.078187              -0.089415   \n423760               -0.514233               -0.543963              -0.501630   \n1616769               0.160043               -0.138616               0.166299   \n5473594              -0.514233               -0.543963              -0.501630   \n...                        ...                     ...                    ...   \n3007592              -0.514233               -0.543963              -0.501630   \n6771053              -0.514233               -0.543963              -0.501630   \n2842438               0.302353                0.110568               0.501685   \n5876236              -0.202508               -0.210813              -0.059370   \n2162949              -0.350747               -0.019795              -0.501630   \n\n         Flow Bytes/s  Flow Packets/s  Flow IAT Mean  Flow IAT Std  \\\n6300475     -0.044793       -0.104969      -0.015411     -0.005265   \n5913184     -0.044922       -0.105976      -0.013454     -0.001905   \n423760      -0.044928        0.122823      -0.015453     -0.005312   \n1616769     -0.044927       -0.105991      -0.003678      0.005398   \n5473594     -0.043752       -0.013365      -0.015453     -0.005312   \n...               ...             ...            ...           ...   \n3007592     -0.044928       -0.105994       0.258664     -0.005312   \n6771053     -0.044928       -0.105948      -0.014052     -0.005312   \n2842438     -0.044235       -0.102984      -0.015441     -0.005292   \n5876236     -0.044923       -0.105977      -0.013358     -0.001728   \n2162949     -0.034537       -0.059679      -0.015452     -0.005312   \n\n         Flow IAT Max  Flow IAT Min  Fwd IAT Total  Fwd IAT Mean  Fwd IAT Std  \\\n6300475     -0.011938     -0.002767      -0.023239     -0.017209    -0.005652   \n5913184     -0.006988     -0.002767      -0.016085     -0.013337    -0.000905   \n423760      -0.011980     -0.002767      -0.023295     -0.017335    -0.005652   \n1616769     -0.000357     -0.002767       0.157841      0.004902     0.005178   \n5473594     -0.011979     -0.002767      -0.023295     -0.017334    -0.005651   \n...               ...           ...            ...           ...          ...   \n3007592      0.080548      0.078858       0.100304      0.256765    -0.005652   \n6771053     -0.011507     -0.002350      -0.022663     -0.015934    -0.005652   \n2842438     -0.011955     -0.002767      -0.023295     -0.017334    -0.005651   \n5876236     -0.007106     -0.002767      -0.016683     -0.013669    -0.000923   \n2162949     -0.011979     -0.002767      -0.023295     -0.017335    -0.005652   \n\n         Fwd IAT Max  Fwd IAT Min  Bwd IAT Total  Bwd IAT Mean  Bwd IAT Std  \\\n6300475    -0.011422    -0.002981      -0.334857     -0.200174    -0.262981   \n5913184    -0.006472    -0.003018      -0.323544     -0.182879    -0.239616   \n423760     -0.011464    -0.003018      -0.334876     -0.200260    -0.262981   \n1616769     0.000159    -0.003018       3.897836      1.093564     0.642553   \n5473594    -0.011464    -0.003018      -0.334876     -0.200260    -0.262981   \n...              ...          ...            ...           ...          ...   \n3007592     0.081064     0.078606      -0.334876     -0.200260    -0.262981   \n6771053    -0.010991    -0.002601      -0.334876     -0.200260    -0.262981   \n2842438    -0.011463    -0.003018      -0.334081     -0.199041    -0.260307   \n5876236    -0.006590    -0.003018      -0.332980     -0.195898    -0.254990   \n2162949    -0.011464    -0.003018      -0.334876     -0.200260    -0.262981   \n\n         Bwd IAT Max  Bwd IAT Min  Fwd PSH Flags  Bwd PSH Flags  \\\n6300475    -0.275231    -0.086333      -0.179931      -0.023297   \n5913184    -0.258876    -0.086376      -0.179931      -0.023297   \n423760     -0.275270    -0.086426      -0.179931      -0.023297   \n1616769     0.492960    -0.086316      -0.179931      -0.023297   \n5473594    -0.275270    -0.086426      -0.179931      -0.023297   \n...              ...          ...            ...            ...   \n3007592    -0.275270    -0.086426      -0.179931      -0.023297   \n6771053    -0.275270    -0.086426      -0.179931      -0.023297   \n2842438    -0.273627    -0.086422      -0.179931      -0.023297   \n5876236    -0.271281    -0.086365      -0.179931      -0.023297   \n2162949    -0.275270    -0.086426      -0.179931      -0.023297   \n\n         Fwd URG Flags  Bwd URG Flags  Fwd Header Length  Bwd Header Length  \\\n6300475      -0.014409            0.0           0.009329           0.004222   \n5913184      -0.014409            0.0           0.009329           0.004232   \n423760       -0.014409            0.0           0.009329           0.004223   \n1616769      -0.014409            0.0           0.009330           0.004261   \n5473594      -0.014409            0.0           0.009329           0.004222   \n...                ...            ...                ...                ...   \n3007592      -0.014409            0.0           0.009329           0.004221   \n6771053      -0.014409            0.0           0.009329           0.004221   \n2842438      -0.014409            0.0           0.009329           0.004228   \n5876236      -0.014409            0.0           0.009329           0.004229   \n2162949      -0.014409            0.0           0.009329           0.004222   \n\n         Fwd Packets/s  Bwd Packets/s  Packet Length Max  Packet Length Mean  \\\n6300475      -0.093281      -0.091193          -0.477361           -0.340576   \n5913184      -0.093808      -0.094031           0.185264            0.095845   \n423760        0.026202       0.549481          -0.580564           -0.679005   \n1616769      -0.093817      -0.094070           0.071414           -0.187852   \n5473594      -0.020939       0.036185          -0.555173           -0.649369   \n...                ...            ...                ...                 ...   \n3007592      -0.093819      -0.094077          -0.580564           -0.679005   \n6771053      -0.093771      -0.094077          -0.580564           -0.679005   \n2842438      -0.092466      -0.084401           0.209017           -0.091056   \n5876236      -0.093807      -0.094040           0.185264            0.013044   \n2162949      -0.069526       0.036185          -0.422484           -0.113363   \n\n         Packet Length Std  Packet Length Variance  FIN Flag Count  \\\n6300475          -0.463334               -0.203713       -0.114025   \n5913184           0.235656               -0.107130       -0.114025   \n423760           -0.600738               -0.206392       -0.114025   \n1616769           0.066182               -0.143281       -0.114025   \n5473594          -0.562935               -0.206189       -0.114025   \n...                    ...                     ...             ...   \n3007592          -0.600738               -0.206392       -0.114025   \n6771053          -0.600738               -0.206392       -0.114025   \n2842438           0.326065               -0.084512       -0.114025   \n5876236           0.272796               -0.098119       -0.114025   \n2162949          -0.424415               -0.201981       -0.114025   \n\n         SYN Flag Count  URG Flag Count  CWE Flag Count  Avg Packet Size  \\\n6300475       -0.205288       -0.193904       -0.049057        -0.310628   \n5913184       -0.205288       -0.193904       -0.049057         0.089143   \n423760        -0.205288        5.157202       -0.049057        -0.696823   \n1616769       -0.205288       -0.193904       -0.049057        -0.235634   \n5473594       -0.205288       -0.193904       -0.049057        -0.663004   \n...                 ...             ...             ...              ...   \n3007592       -0.205288       -0.193904       -0.049057        -0.696823   \n6771053       -0.205288       -0.193904       -0.049057        -0.696823   \n2842438       -0.205288       -0.193904       -0.049057        -0.083400   \n5876236       -0.205288       -0.193904       -0.049057         0.013928   \n2162949       -0.205288       -0.193904       -0.049057         0.077749   \n\n         Avg Fwd Segment Size  Avg Bwd Segment Size  Fwd Avg Bytes/Bulk  \\\n6300475             -0.339401             -0.201760                 0.0   \n5913184              0.758992             -0.078187                 0.0   \n423760              -0.583488             -0.543963                 0.0   \n1616769             -0.088134             -0.138616                 0.0   \n5473594             -0.509305             -0.543963                 0.0   \n...                       ...                   ...                 ...   \n3007592             -0.583488             -0.543963                 0.0   \n6771053             -0.583488             -0.543963                 0.0   \n2842438             -0.535628              0.110568                 0.0   \n5876236              0.758992             -0.210813                 0.0   \n2162949             -0.001986             -0.019795                 0.0   \n\n         Fwd Avg Packets/Bulk  Fwd Avg Bulk Rate  Bwd Avg Bytes/Bulk  \\\n6300475                   0.0                0.0                 0.0   \n5913184                   0.0                0.0                 0.0   \n423760                    0.0                0.0                 0.0   \n1616769                   0.0                0.0                 0.0   \n5473594                   0.0                0.0                 0.0   \n...                       ...                ...                 ...   \n3007592                   0.0                0.0                 0.0   \n6771053                   0.0                0.0                 0.0   \n2842438                   0.0                0.0                 0.0   \n5876236                   0.0                0.0                 0.0   \n2162949                   0.0                0.0                 0.0   \n\n         Bwd Avg Packets/Bulk  Bwd Avg Bulk Rate  Subflow Fwd Packets  \\\n6300475                   0.0                0.0            -0.018775   \n5913184                   0.0                0.0            -0.017323   \n423760                    0.0                0.0            -0.019259   \n1616769                   0.0                0.0            -0.010548   \n5473594                   0.0                0.0            -0.018291   \n...                       ...                ...                  ...   \n3007592                   0.0                0.0            -0.018775   \n6771053                   0.0                0.0            -0.018775   \n2842438                   0.0                0.0            -0.018291   \n5876236                   0.0                0.0            -0.017323   \n2162949                   0.0                0.0            -0.019259   \n\n         Subflow Fwd Bytes  Subflow Bwd Packets  Subflow Bwd Bytes  \\\n6300475          -0.023878            -0.012927          -0.007616   \n5913184          -0.013505            -0.009483          -0.007278   \n423760           -0.024691            -0.014650          -0.007813   \n1616769          -0.009007             0.011187          -0.005949   \n5473594          -0.024320            -0.014650          -0.007813   \n...                    ...                  ...                ...   \n3007592          -0.024691            -0.016372          -0.007813   \n6771053          -0.024691            -0.016372          -0.007813   \n2842438          -0.024452            -0.009483          -0.007061   \n5876236          -0.013505            -0.011205          -0.007526   \n2162949          -0.023722            -0.014650          -0.007662   \n\n         Init Fwd Win Bytes  Init Bwd Win Bytes  Fwd Act Data Packets  \\\n6300475           -0.557987           -0.430904             -0.017215   \n5913184           -0.546362           -0.419995             -0.017215   \n423760            -0.539070           -0.410372             -0.017702   \n1616769            0.985021           -0.415930             -0.016240   \n5473594           -0.505516           -0.430852             -0.017215   \n...                     ...                 ...                   ...   \n3007592           -0.449663           -0.430904             -0.017702   \n6771053            2.823886           -0.430904             -0.017702   \n2842438           -0.125061           -0.419995             -0.017215   \n5876236           -0.545411           -0.419995             -0.017215   \n2162949           -0.557987           -0.430904             -0.017702   \n\n         Fwd Seg Size Min  Active Mean  Active Std  Active Max  Active Min  \\\n6300475          0.031772    -0.079321   -0.064744   -0.097397   -0.065099   \n5913184          0.031772    -0.079321   -0.064744   -0.097397   -0.065099   \n423760           0.031772    -0.079321   -0.064744   -0.097397   -0.065099   \n1616769          0.031772    -0.057800   -0.039814   -0.049389   -0.046643   \n5473594          0.031772    -0.079321   -0.064744   -0.097397   -0.065099   \n...                   ...          ...         ...         ...         ...   \n3007592          0.031772    -0.079321   -0.064744   -0.097397   -0.065099   \n6771053          0.031772    -0.079321   -0.064744   -0.097397   -0.065099   \n2842438          0.031772    -0.079321   -0.064744   -0.097397   -0.065099   \n5876236          0.031772    -0.079321   -0.064744   -0.097397   -0.065099   \n2162949          0.031772    -0.079321   -0.064744   -0.097397   -0.065099   \n\n         Idle Mean  Idle Std  Idle Max  Idle Min  ClusterLabels  ClassLabel  \n6300475  -0.022912 -0.002439 -0.010545 -0.087599           3534           0  \n5913184  -0.022912 -0.002439 -0.010545 -0.087599           1391           0  \n423760   -0.022912 -0.002439 -0.010545 -0.087599            418           0  \n1616769   0.005244  0.002855  0.001712 -0.015847             -1           0  \n5473594  -0.022912 -0.002439 -0.010545 -0.087599           2824           0  \n...            ...       ...       ...       ...            ...         ...  \n3007592   0.209201 -0.002439  0.087033  0.871862           2485           3  \n6771053  -0.022912 -0.002439 -0.010545 -0.087599           1742           0  \n2842438  -0.022912 -0.002439 -0.010545 -0.087599            819           3  \n5876236  -0.022912 -0.002439 -0.010545 -0.087599           1380           0  \n2162949  -0.022912 -0.002439 -0.010545 -0.087599             -1           0  \n\n[90599 rows x 70 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Flow Duration</th>\n      <th>Total Fwd Packets</th>\n      <th>Total Backward Packets</th>\n      <th>Fwd Packets Length Total</th>\n      <th>Bwd Packets Length Total</th>\n      <th>Fwd Packet Length Max</th>\n      <th>Fwd Packet Length Mean</th>\n      <th>Fwd Packet Length Std</th>\n      <th>Bwd Packet Length Max</th>\n      <th>Bwd Packet Length Mean</th>\n      <th>Bwd Packet Length Std</th>\n      <th>Flow Bytes/s</th>\n      <th>Flow Packets/s</th>\n      <th>Flow IAT Mean</th>\n      <th>Flow IAT Std</th>\n      <th>Flow IAT Max</th>\n      <th>Flow IAT Min</th>\n      <th>Fwd IAT Total</th>\n      <th>Fwd IAT Mean</th>\n      <th>Fwd IAT Std</th>\n      <th>Fwd IAT Max</th>\n      <th>Fwd IAT Min</th>\n      <th>Bwd IAT Total</th>\n      <th>Bwd IAT Mean</th>\n      <th>Bwd IAT Std</th>\n      <th>Bwd IAT Max</th>\n      <th>Bwd IAT Min</th>\n      <th>Fwd PSH Flags</th>\n      <th>Bwd PSH Flags</th>\n      <th>Fwd URG Flags</th>\n      <th>Bwd URG Flags</th>\n      <th>Fwd Header Length</th>\n      <th>Bwd Header Length</th>\n      <th>Fwd Packets/s</th>\n      <th>Bwd Packets/s</th>\n      <th>Packet Length Max</th>\n      <th>Packet Length Mean</th>\n      <th>Packet Length Std</th>\n      <th>Packet Length Variance</th>\n      <th>FIN Flag Count</th>\n      <th>SYN Flag Count</th>\n      <th>URG Flag Count</th>\n      <th>CWE Flag Count</th>\n      <th>Avg Packet Size</th>\n      <th>Avg Fwd Segment Size</th>\n      <th>Avg Bwd Segment Size</th>\n      <th>Fwd Avg Bytes/Bulk</th>\n      <th>Fwd Avg Packets/Bulk</th>\n      <th>Fwd Avg Bulk Rate</th>\n      <th>Bwd Avg Bytes/Bulk</th>\n      <th>Bwd Avg Packets/Bulk</th>\n      <th>Bwd Avg Bulk Rate</th>\n      <th>Subflow Fwd Packets</th>\n      <th>Subflow Fwd Bytes</th>\n      <th>Subflow Bwd Packets</th>\n      <th>Subflow Bwd Bytes</th>\n      <th>Init Fwd Win Bytes</th>\n      <th>Init Bwd Win Bytes</th>\n      <th>Fwd Act Data Packets</th>\n      <th>Fwd Seg Size Min</th>\n      <th>Active Mean</th>\n      <th>Active Std</th>\n      <th>Active Max</th>\n      <th>Active Min</th>\n      <th>Idle Mean</th>\n      <th>Idle Std</th>\n      <th>Idle Max</th>\n      <th>Idle Min</th>\n      <th>ClusterLabels</th>\n      <th>ClassLabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6300475</th>\n      <td>-0.024155</td>\n      <td>-0.018775</td>\n      <td>-0.012927</td>\n      <td>-0.023878</td>\n      <td>-0.007616</td>\n      <td>-0.519466</td>\n      <td>-0.339401</td>\n      <td>-0.543296</td>\n      <td>-0.407501</td>\n      <td>-0.201760</td>\n      <td>-0.501630</td>\n      <td>-0.044793</td>\n      <td>-0.104969</td>\n      <td>-0.015411</td>\n      <td>-0.005265</td>\n      <td>-0.011938</td>\n      <td>-0.002767</td>\n      <td>-0.023239</td>\n      <td>-0.017209</td>\n      <td>-0.005652</td>\n      <td>-0.011422</td>\n      <td>-0.002981</td>\n      <td>-0.334857</td>\n      <td>-0.200174</td>\n      <td>-0.262981</td>\n      <td>-0.275231</td>\n      <td>-0.086333</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004222</td>\n      <td>-0.093281</td>\n      <td>-0.091193</td>\n      <td>-0.477361</td>\n      <td>-0.340576</td>\n      <td>-0.463334</td>\n      <td>-0.203713</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.310628</td>\n      <td>-0.339401</td>\n      <td>-0.201760</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018775</td>\n      <td>-0.023878</td>\n      <td>-0.012927</td>\n      <td>-0.007616</td>\n      <td>-0.557987</td>\n      <td>-0.430904</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>3534</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5913184</th>\n      <td>-0.017002</td>\n      <td>-0.017323</td>\n      <td>-0.009483</td>\n      <td>-0.013505</td>\n      <td>-0.007278</td>\n      <td>1.275878</td>\n      <td>0.758992</td>\n      <td>1.634291</td>\n      <td>-0.223685</td>\n      <td>-0.078187</td>\n      <td>-0.089415</td>\n      <td>-0.044922</td>\n      <td>-0.105976</td>\n      <td>-0.013454</td>\n      <td>-0.001905</td>\n      <td>-0.006988</td>\n      <td>-0.002767</td>\n      <td>-0.016085</td>\n      <td>-0.013337</td>\n      <td>-0.000905</td>\n      <td>-0.006472</td>\n      <td>-0.003018</td>\n      <td>-0.323544</td>\n      <td>-0.182879</td>\n      <td>-0.239616</td>\n      <td>-0.258876</td>\n      <td>-0.086376</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004232</td>\n      <td>-0.093808</td>\n      <td>-0.094031</td>\n      <td>0.185264</td>\n      <td>0.095845</td>\n      <td>0.235656</td>\n      <td>-0.107130</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>0.089143</td>\n      <td>0.758992</td>\n      <td>-0.078187</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.017323</td>\n      <td>-0.013505</td>\n      <td>-0.009483</td>\n      <td>-0.007278</td>\n      <td>-0.546362</td>\n      <td>-0.419995</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>1391</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>423760</th>\n      <td>-0.024212</td>\n      <td>-0.019259</td>\n      <td>-0.014650</td>\n      <td>-0.024691</td>\n      <td>-0.007813</td>\n      <td>-0.587215</td>\n      <td>-0.583488</td>\n      <td>-0.543296</td>\n      <td>-0.514233</td>\n      <td>-0.543963</td>\n      <td>-0.501630</td>\n      <td>-0.044928</td>\n      <td>0.122823</td>\n      <td>-0.015453</td>\n      <td>-0.005312</td>\n      <td>-0.011980</td>\n      <td>-0.002767</td>\n      <td>-0.023295</td>\n      <td>-0.017335</td>\n      <td>-0.005652</td>\n      <td>-0.011464</td>\n      <td>-0.003018</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004223</td>\n      <td>0.026202</td>\n      <td>0.549481</td>\n      <td>-0.580564</td>\n      <td>-0.679005</td>\n      <td>-0.600738</td>\n      <td>-0.206392</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>5.157202</td>\n      <td>-0.049057</td>\n      <td>-0.696823</td>\n      <td>-0.583488</td>\n      <td>-0.543963</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.019259</td>\n      <td>-0.024691</td>\n      <td>-0.014650</td>\n      <td>-0.007813</td>\n      <td>-0.539070</td>\n      <td>-0.410372</td>\n      <td>-0.017702</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>418</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1616769</th>\n      <td>0.156313</td>\n      <td>-0.010548</td>\n      <td>0.011187</td>\n      <td>-0.009007</td>\n      <td>-0.005949</td>\n      <td>0.283557</td>\n      <td>-0.088134</td>\n      <td>0.309289</td>\n      <td>0.160043</td>\n      <td>-0.138616</td>\n      <td>0.166299</td>\n      <td>-0.044927</td>\n      <td>-0.105991</td>\n      <td>-0.003678</td>\n      <td>0.005398</td>\n      <td>-0.000357</td>\n      <td>-0.002767</td>\n      <td>0.157841</td>\n      <td>0.004902</td>\n      <td>0.005178</td>\n      <td>0.000159</td>\n      <td>-0.003018</td>\n      <td>3.897836</td>\n      <td>1.093564</td>\n      <td>0.642553</td>\n      <td>0.492960</td>\n      <td>-0.086316</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009330</td>\n      <td>0.004261</td>\n      <td>-0.093817</td>\n      <td>-0.094070</td>\n      <td>0.071414</td>\n      <td>-0.187852</td>\n      <td>0.066182</td>\n      <td>-0.143281</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.235634</td>\n      <td>-0.088134</td>\n      <td>-0.138616</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.010548</td>\n      <td>-0.009007</td>\n      <td>0.011187</td>\n      <td>-0.005949</td>\n      <td>0.985021</td>\n      <td>-0.415930</td>\n      <td>-0.016240</td>\n      <td>0.031772</td>\n      <td>-0.057800</td>\n      <td>-0.039814</td>\n      <td>-0.049389</td>\n      <td>-0.046643</td>\n      <td>0.005244</td>\n      <td>0.002855</td>\n      <td>0.001712</td>\n      <td>-0.015847</td>\n      <td>-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5473594</th>\n      <td>-0.024212</td>\n      <td>-0.018291</td>\n      <td>-0.014650</td>\n      <td>-0.024320</td>\n      <td>-0.007813</td>\n      <td>-0.525444</td>\n      <td>-0.509305</td>\n      <td>-0.450089</td>\n      <td>-0.514233</td>\n      <td>-0.543963</td>\n      <td>-0.501630</td>\n      <td>-0.043752</td>\n      <td>-0.013365</td>\n      <td>-0.015453</td>\n      <td>-0.005312</td>\n      <td>-0.011979</td>\n      <td>-0.002767</td>\n      <td>-0.023295</td>\n      <td>-0.017334</td>\n      <td>-0.005651</td>\n      <td>-0.011464</td>\n      <td>-0.003018</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004222</td>\n      <td>-0.020939</td>\n      <td>0.036185</td>\n      <td>-0.555173</td>\n      <td>-0.649369</td>\n      <td>-0.562935</td>\n      <td>-0.206189</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.663004</td>\n      <td>-0.509305</td>\n      <td>-0.543963</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018291</td>\n      <td>-0.024320</td>\n      <td>-0.014650</td>\n      <td>-0.007813</td>\n      <td>-0.505516</td>\n      <td>-0.430852</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>2824</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3007592</th>\n      <td>0.099460</td>\n      <td>-0.018775</td>\n      <td>-0.016372</td>\n      <td>-0.024691</td>\n      <td>-0.007813</td>\n      <td>-0.587215</td>\n      <td>-0.583488</td>\n      <td>-0.543296</td>\n      <td>-0.514233</td>\n      <td>-0.543963</td>\n      <td>-0.501630</td>\n      <td>-0.044928</td>\n      <td>-0.105994</td>\n      <td>0.258664</td>\n      <td>-0.005312</td>\n      <td>0.080548</td>\n      <td>0.078858</td>\n      <td>0.100304</td>\n      <td>0.256765</td>\n      <td>-0.005652</td>\n      <td>0.081064</td>\n      <td>0.078606</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004221</td>\n      <td>-0.093819</td>\n      <td>-0.094077</td>\n      <td>-0.580564</td>\n      <td>-0.679005</td>\n      <td>-0.600738</td>\n      <td>-0.206392</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.696823</td>\n      <td>-0.583488</td>\n      <td>-0.543963</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018775</td>\n      <td>-0.024691</td>\n      <td>-0.016372</td>\n      <td>-0.007813</td>\n      <td>-0.449663</td>\n      <td>-0.430904</td>\n      <td>-0.017702</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>0.209201</td>\n      <td>-0.002439</td>\n      <td>0.087033</td>\n      <td>0.871862</td>\n      <td>2485</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6771053</th>\n      <td>-0.023580</td>\n      <td>-0.018775</td>\n      <td>-0.016372</td>\n      <td>-0.024691</td>\n      <td>-0.007813</td>\n      <td>-0.587215</td>\n      <td>-0.583488</td>\n      <td>-0.543296</td>\n      <td>-0.514233</td>\n      <td>-0.543963</td>\n      <td>-0.501630</td>\n      <td>-0.044928</td>\n      <td>-0.105948</td>\n      <td>-0.014052</td>\n      <td>-0.005312</td>\n      <td>-0.011507</td>\n      <td>-0.002350</td>\n      <td>-0.022663</td>\n      <td>-0.015934</td>\n      <td>-0.005652</td>\n      <td>-0.010991</td>\n      <td>-0.002601</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004221</td>\n      <td>-0.093771</td>\n      <td>-0.094077</td>\n      <td>-0.580564</td>\n      <td>-0.679005</td>\n      <td>-0.600738</td>\n      <td>-0.206392</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.696823</td>\n      <td>-0.583488</td>\n      <td>-0.543963</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018775</td>\n      <td>-0.024691</td>\n      <td>-0.016372</td>\n      <td>-0.007813</td>\n      <td>2.823886</td>\n      <td>-0.430904</td>\n      <td>-0.017702</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>1742</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2842438</th>\n      <td>-0.024178</td>\n      <td>-0.018291</td>\n      <td>-0.009483</td>\n      <td>-0.024452</td>\n      <td>-0.007061</td>\n      <td>-0.547363</td>\n      <td>-0.535628</td>\n      <td>-0.483162</td>\n      <td>0.302353</td>\n      <td>0.110568</td>\n      <td>0.501685</td>\n      <td>-0.044235</td>\n      <td>-0.102984</td>\n      <td>-0.015441</td>\n      <td>-0.005292</td>\n      <td>-0.011955</td>\n      <td>-0.002767</td>\n      <td>-0.023295</td>\n      <td>-0.017334</td>\n      <td>-0.005651</td>\n      <td>-0.011463</td>\n      <td>-0.003018</td>\n      <td>-0.334081</td>\n      <td>-0.199041</td>\n      <td>-0.260307</td>\n      <td>-0.273627</td>\n      <td>-0.086422</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004228</td>\n      <td>-0.092466</td>\n      <td>-0.084401</td>\n      <td>0.209017</td>\n      <td>-0.091056</td>\n      <td>0.326065</td>\n      <td>-0.084512</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>-0.083400</td>\n      <td>-0.535628</td>\n      <td>0.110568</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.018291</td>\n      <td>-0.024452</td>\n      <td>-0.009483</td>\n      <td>-0.007061</td>\n      <td>-0.125061</td>\n      <td>-0.419995</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>819</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5876236</th>\n      <td>-0.017600</td>\n      <td>-0.017323</td>\n      <td>-0.011205</td>\n      <td>-0.013505</td>\n      <td>-0.007526</td>\n      <td>1.275878</td>\n      <td>0.758992</td>\n      <td>1.634291</td>\n      <td>-0.202508</td>\n      <td>-0.210813</td>\n      <td>-0.059370</td>\n      <td>-0.044923</td>\n      <td>-0.105977</td>\n      <td>-0.013358</td>\n      <td>-0.001728</td>\n      <td>-0.007106</td>\n      <td>-0.002767</td>\n      <td>-0.016683</td>\n      <td>-0.013669</td>\n      <td>-0.000923</td>\n      <td>-0.006590</td>\n      <td>-0.003018</td>\n      <td>-0.332980</td>\n      <td>-0.195898</td>\n      <td>-0.254990</td>\n      <td>-0.271281</td>\n      <td>-0.086365</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004229</td>\n      <td>-0.093807</td>\n      <td>-0.094040</td>\n      <td>0.185264</td>\n      <td>0.013044</td>\n      <td>0.272796</td>\n      <td>-0.098119</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>0.013928</td>\n      <td>0.758992</td>\n      <td>-0.210813</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.017323</td>\n      <td>-0.013505</td>\n      <td>-0.011205</td>\n      <td>-0.007526</td>\n      <td>-0.545411</td>\n      <td>-0.419995</td>\n      <td>-0.017215</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>1380</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2162949</th>\n      <td>-0.024212</td>\n      <td>-0.019259</td>\n      <td>-0.014650</td>\n      <td>-0.023722</td>\n      <td>-0.007662</td>\n      <td>-0.425813</td>\n      <td>-0.001986</td>\n      <td>-0.543296</td>\n      <td>-0.350747</td>\n      <td>-0.019795</td>\n      <td>-0.501630</td>\n      <td>-0.034537</td>\n      <td>-0.059679</td>\n      <td>-0.015452</td>\n      <td>-0.005312</td>\n      <td>-0.011979</td>\n      <td>-0.002767</td>\n      <td>-0.023295</td>\n      <td>-0.017335</td>\n      <td>-0.005652</td>\n      <td>-0.011464</td>\n      <td>-0.003018</td>\n      <td>-0.334876</td>\n      <td>-0.200260</td>\n      <td>-0.262981</td>\n      <td>-0.275270</td>\n      <td>-0.086426</td>\n      <td>-0.179931</td>\n      <td>-0.023297</td>\n      <td>-0.014409</td>\n      <td>0.0</td>\n      <td>0.009329</td>\n      <td>0.004222</td>\n      <td>-0.069526</td>\n      <td>0.036185</td>\n      <td>-0.422484</td>\n      <td>-0.113363</td>\n      <td>-0.424415</td>\n      <td>-0.201981</td>\n      <td>-0.114025</td>\n      <td>-0.205288</td>\n      <td>-0.193904</td>\n      <td>-0.049057</td>\n      <td>0.077749</td>\n      <td>-0.001986</td>\n      <td>-0.019795</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.019259</td>\n      <td>-0.023722</td>\n      <td>-0.014650</td>\n      <td>-0.007662</td>\n      <td>-0.557987</td>\n      <td>-0.430904</td>\n      <td>-0.017702</td>\n      <td>0.031772</td>\n      <td>-0.079321</td>\n      <td>-0.064744</td>\n      <td>-0.097397</td>\n      <td>-0.065099</td>\n      <td>-0.022912</td>\n      <td>-0.002439</td>\n      <td>-0.010545</td>\n      <td>-0.087599</td>\n      <td>-1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>90599 rows × 70 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_major"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def sampling(df):\n",
    "    name = df.name\n",
    "    frac = 1.0\n",
    "    return df.sample(frac=frac)\n",
    "result = df_major.groupby('ClusterLabels', group_keys=False).apply(sampling)\n",
    "result = result.drop([\"ClusterLabels\"], axis=1)\n",
    "result = result.append(df_minor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0    71634\n3    12505\n4     3997\n1     1413\n2     1050\n5     1018\n7       36\n6       23\nName: ClassLabel, dtype: int64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['ClassLabel'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "result.to_csv('./ids_data/CIC_Collection_clean_sample.csv', index=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split train set and test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "df_clean_sample = pd.read_csv('./ids_data/CIC_Collection_clean_sample.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X = df_clean_sample.drop(['ClassLabel'],axis=1).values\n",
    "y = df_clean_sample.iloc[:, -1].values.reshape(-1,1)\n",
    "y = np.ravel(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0,stratify = y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering\n",
    "### Feature selection by genetic algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "\n",
    "evolved_estimator = GAFeatureSelectionCV(\n",
    "    estimator=clf,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    population_size=100,\n",
    "    generations=15,\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "    keep_top_k=2,\n",
    "    elitism=True,\n",
    ")\n",
    "\n",
    "evolved_estimator.fit(X, y)\n",
    "features = evolved_estimator.best_features_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Original X Shape: {X.shape}\")\n",
    "\n",
    "X_best_features = X[:, features]\n",
    "\n",
    "print(f\"Best Features X Shape: {X_best_features.shape}\")\n",
    "\n",
    "pd.DataFrame(X_best_features).to_csv('./ids_data/X_best_features.csv', index=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature selection by Fast Correlation Based Filter (FCBF)\n",
    "GitHub repo: https://github.com/SantiagoEG/FCBF_module"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from FCBF_module import FCBF, FCBFK, FCBFiP, get_i\n",
    "fcbf = FCBFK(k = 20)\n",
    "X_bf = pd.read_csv('./ids_data/X_best_features.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_bbf = fcbf.fit_transform(X_bf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resplit train & test sets after feature selection from genetic algorithm\n",
    "## and fast correlation based filter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bbf,y, train_size = 0.8, test_size = 0.2, random_state = 0,stratify = y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Synthetic Minority Oversampling Technique (SMOTE) to solve class imbalance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(n_jobs=-1,sampling_strategy='not majority')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Intrusion Detection System Model Training\n",
    "### Training four base learners: Random forest, XGBoost (Isolation forest for anomaly)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Applying Random Forest\n",
    "\n",
    "randomforest = RandomForestClassifier(random_state=7)\n",
    "randomforest.fit(X_train, y_train)\n",
    "rf_score = randomforest.score(X_test, y_test)\n",
    "y_predict = randomforest.predict(X_test)\n",
    "y_actual = y_test\n",
    "print('Accuracy of RF: '+ str(rf_score))\n",
    "precision,recall, fscore, none= precision_recall_fscore_support(y_actual, y_predict, average='weighted')\n",
    "print('Precision of RF: '+(str(precision)))\n",
    "print('Recall of RF: '+(str(recall)))\n",
    "print('F1-score of RF: '+(str(fscore))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(7,5=7))\n",
    "sns.heatmap(cm, annot=True,linewidth=0.5,linecolor=\"blue\",fmt=\".0f\", ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
